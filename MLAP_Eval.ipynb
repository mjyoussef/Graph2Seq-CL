{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFQxATSSWofs",
        "outputId": "4901f41a-cff9-42fe-8806-fe6240a65674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Google Drive Folder already existed.\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "NOTEBOOK_NAME = \"MLAP_test_eval\"\n",
        "\n",
        "# --- do not change below this ---\n",
        "DRIVE_PATH = \"/content/drive/\"\n",
        "drive.mount(DRIVE_PATH, force_remount=True)\n",
        "\n",
        "# shell commands for directory with space must be\n",
        "# quoted, but not necessary in python\n",
        "COLAB_PATH = \"Colab Notebooks\"\n",
        "COLLAB_PATH_ESC = f\"\\\"{COLAB_PATH}\\\"\"\n",
        "\n",
        "# python path\n",
        "nb_path = (\n",
        "    \"/\".join(('drive/MyDrive', \n",
        "              COLAB_PATH, \n",
        "              \"venv_\" + NOTEBOOK_NAME)\n",
        "    )\n",
        ")\n",
        "\n",
        "# shell path\n",
        "nb_path_bash = (\n",
        "    \"/\".join(('drive/MyDrive', \n",
        "              COLLAB_PATH_ESC, \n",
        "              \"venv_\" + NOTEBOOK_NAME)\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "  os.makedirs(nb_path)\n",
        "except FileExistsError:\n",
        "  # already created in G-drive\n",
        "  print(\"Google Drive Folder already existed.\")\n",
        "\n",
        "try:\n",
        "  # create symlink from drive to workspace\n",
        "  os.symlink(nb_path, \"/content/notebooks\")\n",
        "except FileExistsError:\n",
        "  # already created in G-drive\n",
        "  print(\"Symlink already existed.\")\n",
        "\n",
        "sys.path.insert(0, nb_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QJIm9RQtWpcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440047b1-52d8-4fe2-cdd4-356bf9f8479e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/616.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/616.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.2/616.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet torch_geometric ogb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkKs0jaewe9y"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F5LoicGwwajW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.utils import dropout_edge, degree, to_undirected, scatter, to_networkx\n",
        "\n",
        "class ASTNodeEncoder(torch.nn.Module):\n",
        "    '''\n",
        "        Input:\n",
        "            x: default node feature. the first and second column represents node type and node attributes.\n",
        "            depth: The depth of the node in the AST.\n",
        "\n",
        "        Output:\n",
        "            emb_dim-dimensional vector\n",
        "\n",
        "    '''\n",
        "    def __init__(self, emb_dim, num_nodetypes, num_nodeattributes, max_depth):\n",
        "        super(ASTNodeEncoder, self).__init__()\n",
        "\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "        self.type_encoder = torch.nn.Embedding(num_nodetypes, emb_dim)\n",
        "        self.attribute_encoder = torch.nn.Embedding(num_nodeattributes, emb_dim)\n",
        "        self.depth_encoder = torch.nn.Embedding(self.max_depth + 1, emb_dim)\n",
        "\n",
        "        self.node_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(3 * emb_dim, 2 * emb_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(2 * emb_dim, emb_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, depth):\n",
        "        depth[depth > self.max_depth] = self.max_depth\n",
        "        mlp_input = torch.hstack(\n",
        "            (\n",
        "                self.type_encoder(x[:,0]), \n",
        "                self.attribute_encoder(x[:,1]), \n",
        "                self.depth_encoder(depth)\n",
        "             )\n",
        "        )\n",
        "        return self.node_mlp(mlp_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FamuAT6rV3G6"
      },
      "source": [
        "### Utils - AST / MLAP\n",
        "\n",
        "Utilities for editing and parsing the AST inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a8ZPzicd-pjb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.utils import dropout_edge, degree, to_undirected, scatter, to_networkx\n",
        "import networkx as nx\n",
        "\n",
        "def get_vocab_mapping(seq_list, num_vocab):\n",
        "    '''\n",
        "        Input:\n",
        "            seq_list: a list of sequences\n",
        "            num_vocab: vocabulary size\n",
        "        Output:\n",
        "            vocab2idx:\n",
        "                A dictionary that maps vocabulary into integer index.\n",
        "                Additioanlly, we also index '__UNK__' and '__EOS__'\n",
        "                '__UNK__' : out-of-vocabulary term\n",
        "                '__EOS__' : end-of-sentence\n",
        "\n",
        "            idx2vocab:\n",
        "                A list that maps idx to actual vocabulary.\n",
        "    '''\n",
        "\n",
        "    vocab_cnt = {}\n",
        "    vocab_list = []\n",
        "    for seq in seq_list:\n",
        "        for w in seq:\n",
        "            if w in vocab_cnt:\n",
        "                vocab_cnt[w] += 1\n",
        "            else:\n",
        "                vocab_cnt[w] = 1\n",
        "                vocab_list.append(w)\n",
        "\n",
        "    cnt_list = np.array([vocab_cnt[w] for w in vocab_list])\n",
        "    topvocab = np.argsort(-cnt_list, kind = 'stable')[:num_vocab]\n",
        "\n",
        "    print('Coverage of top {} vocabulary:'.format(num_vocab))\n",
        "    print(float(np.sum(cnt_list[topvocab]))/np.sum(cnt_list))\n",
        "\n",
        "    vocab2idx = {vocab_list[vocab_idx]: idx for idx, vocab_idx in enumerate(topvocab)}\n",
        "    idx2vocab = [vocab_list[vocab_idx] for vocab_idx in topvocab]\n",
        "\n",
        "    vocab2idx['__UNK__'] = num_vocab\n",
        "    idx2vocab.append('__UNK__')\n",
        "\n",
        "    vocab2idx['__EOS__'] = num_vocab + 1\n",
        "    idx2vocab.append('__EOS__')\n",
        "\n",
        "    # test the correspondence between vocab2idx and idx2vocab\n",
        "    for idx, vocab in enumerate(idx2vocab):\n",
        "        assert(idx == vocab2idx[vocab])\n",
        "\n",
        "    # test that the idx of '__EOS__' is len(idx2vocab) - 1.\n",
        "    # This fact will be used in decode_arr_to_seq, when finding __EOS__\n",
        "    assert(vocab2idx['__EOS__'] == len(idx2vocab) - 1)\n",
        "\n",
        "    return vocab2idx, idx2vocab\n",
        "\n",
        "def augment_edge(data):\n",
        "    '''\n",
        "        Input:\n",
        "            data: PyG data object\n",
        "        Output:\n",
        "            data (edges are augmented in the following ways):\n",
        "                data.edge_index: Added next-token edge. The inverse edges were also added.\n",
        "                data.edge_attr (torch.Long):\n",
        "                    data.edge_attr[:,0]: whether it is AST edge (0) for next-token edge (1)\n",
        "                    data.edge_attr[:,1]: whether it is original direction (0) or inverse direction (1)\n",
        "    '''\n",
        "    ##### AST edge\n",
        "    edge_index_ast = data.edge_index\n",
        "    edge_attr_ast = torch.zeros((edge_index_ast.size(1), 2))\n",
        "\n",
        "    ##### Inverse AST edge\n",
        "    edge_index_ast_inverse = torch.stack([edge_index_ast[1], edge_index_ast[0]], dim = 0)\n",
        "    edge_attr_ast_inverse = torch.cat([torch.zeros(edge_index_ast_inverse.size(1), 1), torch.ones(edge_index_ast_inverse.size(1), 1)], dim = 1)\n",
        "\n",
        "    ##### Next-token edge\n",
        "\n",
        "    ## Obtain attributed nodes and get their indices in dfs order\n",
        "    # attributed_node_idx = torch.where(data.node_is_attributed.view(-1,) == 1)[0]\n",
        "    # attributed_node_idx_in_dfs_order = attributed_node_idx[torch.argsort(data.node_dfs_order[attributed_node_idx].view(-1,))]\n",
        "\n",
        "    ## Since the nodes are already sorted in dfs ordering in our case, we can just do the following.\n",
        "    attributed_node_idx_in_dfs_order = torch.where(data.node_is_attributed.view(-1,) == 1)[0]\n",
        "\n",
        "    ## build next token edge\n",
        "    # Given: attributed_node_idx_in_dfs_order\n",
        "    #        [1, 3, 4, 5, 8, 9, 12]\n",
        "    # Output:\n",
        "    #    [[1, 3, 4, 5, 8, 9]\n",
        "    #     [3, 4, 5, 8, 9, 12]\n",
        "    edge_index_nextoken = torch.stack([attributed_node_idx_in_dfs_order[:-1], attributed_node_idx_in_dfs_order[1:]], dim = 0)\n",
        "    edge_attr_nextoken = torch.cat([torch.ones(edge_index_nextoken.size(1), 1), torch.zeros(edge_index_nextoken.size(1), 1)], dim = 1)\n",
        "\n",
        "    ##### Inverse next-token edge\n",
        "    edge_index_nextoken_inverse = torch.stack([edge_index_nextoken[1], edge_index_nextoken[0]], dim = 0)\n",
        "    edge_attr_nextoken_inverse = torch.ones((edge_index_nextoken.size(1), 2))\n",
        "\n",
        "    data.edge_index = torch.cat([edge_index_ast, edge_index_ast_inverse, edge_index_nextoken, edge_index_nextoken_inverse], dim = 1)\n",
        "    data.edge_attr = torch.cat([edge_attr_ast,   edge_attr_ast_inverse, edge_attr_nextoken,  edge_attr_nextoken_inverse], dim = 0)\n",
        "\n",
        "    return data\n",
        "\n",
        "def encode_y_to_arr(data, vocab2idx, max_seq_len):\n",
        "    '''\n",
        "    Input:\n",
        "        data: PyG graph object\n",
        "        output: add y_arr to data \n",
        "    '''\n",
        "    # PyG >= 1.5.0\n",
        "    seq = data.y\n",
        "    data.y_arr = encode_seq_to_arr(seq, vocab2idx, max_seq_len)\n",
        "    return data\n",
        "\n",
        "def encode_seq_to_arr(seq, vocab2idx, max_seq_len):\n",
        "    '''\n",
        "    Input:\n",
        "        seq: A list of words\n",
        "        output: add y_arr (torch.Tensor)\n",
        "    '''\n",
        "    augmented_seq = seq[:max_seq_len] + ['__EOS__'] * max(0, max_seq_len - len(seq))\n",
        "    return torch.tensor([[vocab2idx[w] if w in vocab2idx else vocab2idx['__UNK__'] for w in augmented_seq]], dtype = torch.long)\n",
        "\n",
        "\n",
        "def decode_arr_to_seq(arr, idx2vocab):\n",
        "    '''\n",
        "        Input: torch 1d array: y_arr\n",
        "        Output: a sequence of words.\n",
        "    '''\n",
        "    # find the position of __EOS__ (the last vocab in idx2vocab)\n",
        "    eos_idx_list = (arr == len(idx2vocab) - 1).nonzero() \n",
        "    if len(eos_idx_list) > 0:\n",
        "        # find the smallest __EOS__\n",
        "        clippted_arr = arr[: torch.min(eos_idx_list)] \n",
        "    else:\n",
        "        clippted_arr = arr\n",
        "\n",
        "    return list(map(lambda x: idx2vocab[x], clippted_arr.cpu()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP9s6wJ1-0Cj"
      },
      "source": [
        "### Utils - CAP / GRACE\n",
        "Utilities for generating Graph Contrastive Pairs\n",
        "\n",
        "See: [Graph Contrastive Learning with Adaptive Augmentation (2020) - Zhu, Xu, Yu, Liu, Wu, Wang](https://arxiv.org/abs/2010.14945)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6QXwE3BnV2vf"
      },
      "outputs": [],
      "source": [
        "# ---- CAP functions ----\n",
        "# from: https://github.com/CRIPAC-DIG/GCA/blob/cd6a9f0cf06c0b8c48e108a6aab743585f6ba6f1/pGRACE/functional.py\n",
        "# and: https://github.com/CRIPAC-DIG/GCA/blob/cd6a9f0cf06c0b8c48e108a6aab743585f6ba6f1/pGRACE/utils.py\n",
        "def compute_pr(edge_index, damp: float = 0.85, k: int = 10):\n",
        "    # page rank\n",
        "    # interesting comment: https://github.com/CRIPAC-DIG/GCA/issues/4\n",
        "    num_nodes = edge_index.max().item() + 1\n",
        "    deg_out = degree(edge_index[0])\n",
        "    x = torch.ones((num_nodes, )).to(edge_index.device).to(torch.float32)\n",
        "\n",
        "    for i in range(k):\n",
        "        edge_msg = x[edge_index[0]] / deg_out[edge_index[0]]\n",
        "        agg_msg = scatter(edge_msg, edge_index[1], reduce='sum')\n",
        "\n",
        "        x = (1 - damp) * x + damp * agg_msg\n",
        "\n",
        "    return x\n",
        "\n",
        "def eigenvector_centrality(data):\n",
        "    graph = to_networkx(data)\n",
        "    x = nx.eigenvector_centrality_numpy(graph)\n",
        "    x = [x[i] for i in range(data.num_nodes)]\n",
        "    return torch.tensor(x, dtype=torch.float32).to(data.edge_index.device)\n",
        "\n",
        "def drop_feature(x, drop_prob):\n",
        "    drop_mask = torch.empty((x.size(1),), dtype=torch.float32, device=x.device).uniform_(0, 1) < drop_prob\n",
        "    x = x.clone()\n",
        "    x[:, drop_mask] = 0\n",
        "    return x\n",
        "\n",
        "def drop_feature_weighted(x, w, p: float, threshold: float = 0.7):\n",
        "    w = w / w.mean() * p\n",
        "    w = w.where(w < threshold, torch.ones_like(w) * threshold)\n",
        "    drop_prob = w.repeat(x.size(0)).view(x.size(0), -1)\n",
        "    drop_mask = torch.bernoulli(drop_prob).to(torch.bool)\n",
        "    x = x.clone()\n",
        "    x[drop_mask] = 0.\n",
        "    return x\n",
        "\n",
        "def drop_feature_weighted_2(x, w, p: float, threshold: float = 0.7, dgi_task=False):\n",
        "    w = w / w.mean() * p\n",
        "    # if (dgi_task):\n",
        "    #     threshold = 0.9\n",
        "    w = w.where(w < threshold, torch.ones_like(w) * threshold)\n",
        "    drop_prob = w\n",
        "\n",
        "    if (dgi_task):\n",
        "        drop_mask = torch.bernoulli(1. - drop_prob).to(torch.bool)\n",
        "    else:\n",
        "        drop_mask = torch.bernoulli(drop_prob).to(torch.bool)\n",
        "\n",
        "    x = x.clone()\n",
        "    x[:, drop_mask] = 0.\n",
        "    return x\n",
        "\n",
        "def feature_drop_weights(x, node_c):\n",
        "    x = x.to(torch.bool).to(torch.float32)\n",
        "    w = x.t() @ node_c\n",
        "    w = w.log()\n",
        "    s = (w.max() - w) / (w.max() - w.mean())\n",
        "    return s\n",
        "\n",
        "def feature_drop_weights_dense(x, node_c):\n",
        "    x = x.abs()\n",
        "    w = x.t() @ node_c\n",
        "    w = w.log()\n",
        "    s = (w.max() - w) / (w.max() - w.mean())\n",
        "    return s\n",
        "\n",
        "\n",
        "def drop_edge_weighted(edge_index, edge_weights, p: float, threshold: float = 1., dgi_task=False):\n",
        "    edge_weights = edge_weights / edge_weights.mean() * p\n",
        "    # if (dgi_task):\n",
        "    #     threshold = 0.9\n",
        "\n",
        "    edge_weights = edge_weights.where(edge_weights < threshold, torch.ones_like(edge_weights) * threshold)\n",
        "\n",
        "    if (dgi_task): \n",
        "        # drop edges by importance\n",
        "        sel_mask = torch.bernoulli(edge_weights).to(torch.bool)\n",
        "    else:\n",
        "        sel_mask = torch.bernoulli(1. - edge_weights).to(torch.bool)\n",
        "    return edge_index[:, sel_mask]\n",
        "\n",
        "def degree_drop_weights(edge_index):\n",
        "    edge_index_ = to_undirected(edge_index)\n",
        "    deg = degree(edge_index_[1])\n",
        "    deg_col = deg[edge_index[1]].to(torch.float32)\n",
        "    s_col = torch.log(deg_col)\n",
        "    weights = (s_col.max() - s_col) / (s_col.max() - s_col.mean())\n",
        "    return weights\n",
        "\n",
        "def pr_drop_weights(edge_index, aggr: str = 'sink', k: int = 10):\n",
        "    pv = compute_pr(edge_index, k=k)\n",
        "    pv_row = pv[edge_index[0]].to(torch.float32)\n",
        "    pv_col = pv[edge_index[1]].to(torch.float32)\n",
        "    s_row = torch.log(pv_row)\n",
        "    s_col = torch.log(pv_col)\n",
        "    if aggr == 'sink':\n",
        "        s = s_col\n",
        "    elif aggr == 'source':\n",
        "        s = s_row\n",
        "    elif aggr == 'mean':\n",
        "        s = (s_col + s_row) * 0.5\n",
        "    else:\n",
        "        s = s_col\n",
        "    weights = (s.max() - s) / (s.max() - s.mean())\n",
        "    return weights\n",
        "\n",
        "def evc_drop_weights(data):\n",
        "    evc = eigenvector_centrality(data)\n",
        "    evc = evc.where(evc > 0, torch.zeros_like(evc))\n",
        "    evc = evc + 1e-8\n",
        "    s = evc.log()\n",
        "\n",
        "    edge_index = data.edge_index\n",
        "    s_row, s_col = s[edge_index[0]], s[edge_index[1]]\n",
        "    s = s_col\n",
        "    return (s.max() - s) / (s.max() - s.mean())\n",
        "\n",
        "def graph_perturb(data, drop_scheme='pr'):\n",
        "  if drop_scheme == 'degree':\n",
        "      drop_weights = degree_drop_weights(data.edge_index)\n",
        "      edge_index_ = to_undirected(data.edge_index)\n",
        "      node_deg = degree(edge_index_[1])\n",
        "      feature_weights = feature_drop_weights(data.x, node_c=node_deg)\n",
        "  elif drop_scheme == 'pr':\n",
        "      drop_weights = pr_drop_weights(data.edge_index, aggr='sink', k=200)\n",
        "      node_pr = compute_pr(data.edge_index)\n",
        "      feature_weights = feature_drop_weights(data.x, node_c=node_pr)\n",
        "  elif drop_scheme == 'evc':\n",
        "      drop_weights = evc_drop_weights(data)\n",
        "      node_evc = eigenvector_centrality(data)\n",
        "      feature_weights = feature_drop_weights(data.x, node_c=node_evc)\n",
        "  else:\n",
        "      feature_weights = torch.ones((data.x.size(1),))\n",
        "      drop_weights = None\n",
        "  \n",
        "  return feature_weights, drop_weights\n",
        "\n",
        "def drop_edge(data, drop_edge_rate, drop_weights, drop_scheme='pr', drop_edge_weighted_threshold=0.7, dgi_task=False):\n",
        "  if drop_scheme == 'uniform':\n",
        "      return dropout_edge(data.edge_index, p=drop_edge_rate)[0]\n",
        "  elif drop_scheme in ['degree', 'evc', 'pr']:\n",
        "      return drop_edge_weighted(\n",
        "          data.edge_index, \n",
        "          drop_weights, \n",
        "          p=drop_edge_rate, \n",
        "          threshold=drop_edge_weighted_threshold,\n",
        "          dgi_task=dgi_task\n",
        "        )\n",
        "  else:\n",
        "      raise Exception(f'undefined drop scheme: {drop_scheme}')\n",
        "\n",
        "def get_contrastive_graph_pair(data, drop_scheme='pr', drop_feature_rates=(0.7, 0.7), drop_edge_rates=(0.5, 0.5), dgi_task=False):\n",
        "  # use augmentation scheme to determine the weights of each node\n",
        "  # i.e. pagerank, eigenvector centrality, node degree\n",
        "  feat_weights, drop_weights = graph_perturb(data, drop_scheme)\n",
        "\n",
        "  # apply drop edge according to computed features\n",
        "  dr_e_1, dr_e_2 = drop_edge_rates\n",
        "  edge_index_1 = drop_edge(data, dr_e_1, drop_weights, drop_scheme, dgi_task=dgi_task)\n",
        "\n",
        "  if (not dgi_task):\n",
        "    edge_index_2 = drop_edge(data, dr_e_2, drop_weights, drop_scheme)\n",
        "\n",
        "  dr_f_1, dr_f_2 = drop_feature_rates\n",
        "\n",
        "  if drop_scheme in ['pr', 'degree', 'evc']:\n",
        "    # graph-aware drop feature\n",
        "    x_1 = drop_feature_weighted_2(data.x, feat_weights, dr_f_1, dgi_task=dgi_task)\n",
        "    #e_1 = drop_feature_weighted_2(data.edge_attr, feat_weights, dr_f_1)\n",
        "\n",
        "    if not dgi_task:\n",
        "        x_2 = drop_feature_weighted_2(data.x, feat_weights, dr_f_2, dgi_task=dgi_task)\n",
        "        #e_2 = drop_feature_weighted_2(data.edge_attr, feat_weights, dr_f_2)\n",
        "  else:\n",
        "    # naive drop feature\n",
        "    x_1 = drop_feature(data.x, dr_f_1)\n",
        "    #e_1 = drop_feature(data.edge_attr, dr_f_1)\n",
        "    \n",
        "    x_2 = drop_feature(data.x, dr_f_2)\n",
        "    e_2 = drop_feature(data.edge_attr, dr_f_2)\n",
        "  \n",
        "  if dgi_task:\n",
        "      return (x_1, edge_index_1)\n",
        "\n",
        "  return (\n",
        "      # graph 1\n",
        "      (x_1, edge_index_1),\n",
        "      # graph 2\n",
        "      (x_2, edge_index_2)\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSAs0mAoVjXQ"
      },
      "source": [
        "### Decoders\n",
        "\n",
        "Specific to the AST code task. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JhqdRjDJVpbo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class LinearDecoder(torch.nn.Module):\n",
        "    def __init__(self, dim_h, max_seq_len, vocab2idx, device):\n",
        "        \"\"\"\n",
        "        Noted in the MLAP paper to have performed better than the LSTM\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.vocab2idx = vocab2idx\n",
        "        self.decoders = nn.ModuleList(\n",
        "            [nn.Linear(dim_h, len(vocab2idx)) for _ in range(max_seq_len)]\n",
        "        )\n",
        "\n",
        "    def forward(self, batch_size, layer_reps, labels, training=False):\n",
        "        return [d(layer_reps[-1]) for d in self.decoders]\n",
        "\n",
        "\n",
        "class LSTMDecoder(torch.nn.Module):\n",
        "    def __init__(self, dim_h, max_seq_len, vocab2idx, device):\n",
        "        super(LSTMDecoder, self).__init__()\n",
        "        \n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.vocab2idx = vocab2idx\n",
        "\n",
        "        self.lstm = nn.LSTMCell(dim_h, dim_h)\n",
        "        self.w_hc = nn.Linear(dim_h * 2, dim_h)\n",
        "        self.layernorm = nn.LayerNorm(dim_h)\n",
        "        self.vocab_encoder = nn.Embedding(len(vocab2idx), dim_h)\n",
        "        self.vocab_bias = nn.Parameter(torch.zeros(len(vocab2idx)))\n",
        "\n",
        "        self.device = device\n",
        "    \n",
        "    def forward(self, batch_size, layer_reps, labels, training=False):\n",
        "        if (training):\n",
        "            batched_label = torch.vstack(\n",
        "                [\n",
        "                    encode_seq_to_arr(label, self.vocab2idx, self.max_seq_len - 1) \n",
        "                    for label in labels\n",
        "                ]\n",
        "            )\n",
        "            batched_label = torch.hstack((torch.zeros((batch_size, 1), dtype=torch.int64), batched_label))\n",
        "            true_emb = self.vocab_encoder(batched_label.to(device=self.device))\n",
        "        \n",
        "        h_t, c_t = layer_reps[-1].clone(), layer_reps[-1].clone()\n",
        "\n",
        "        layer_reps = layer_reps.transpose(0,1)\n",
        "        output = []\n",
        "\n",
        "        pred_emb = self.vocab_encoder(torch.zeros((batch_size), dtype=torch.int64, device=self.device))\n",
        "        vocab_mat = self.vocab_encoder(torch.arange(len(self.vocab2idx), dtype=torch.int64, device=self.device))\n",
        "\n",
        "        for i in range(self.max_seq_len):\n",
        "            if training: \n",
        "                # teacher forcing\n",
        "                input = true_emb[:, i]\n",
        "            else:\n",
        "                input = pred_emb\n",
        "            \n",
        "            h_t, c_t = self.lstm(input, (h_t, c_t))\n",
        "\n",
        "            # (batch_size, L + 1)\n",
        "            a = F.softmax(torch.bmm(layer_reps, h_t.unsqueeze(-1)).squeeze(-1), dim=1)  \n",
        "            context = torch.bmm(a.unsqueeze(1), layer_reps).squeeze(1)\n",
        "\n",
        "            # (batch_size, dim_h)\n",
        "            pred_emb = torch.tanh(self.layernorm(self.w_hc(torch.hstack((h_t, context)))))  \n",
        "\n",
        "            # (batch_size, len(vocab)) x max_seq_len\n",
        "            output.append(torch.matmul(pred_emb, vocab_mat.T) + self.vocab_bias.unsqueeze(0))\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GIN\n",
        "\n",
        "Graph Isomorphism Network\n",
        "\n",
        "See: [How Powerful are Graph Neural Networks? (2018) - Xu, Hu, Leskovec, Jegelka](https://arxiv.org/abs/1810.00826v3)"
      ],
      "metadata": {
        "id": "SnvaaBCBTUfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear, BatchNorm1d\n",
        "\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops\n",
        "\n",
        "class GINConv(MessagePassing):\n",
        "    def __init__(self, dim_h, mlp, **kwargs):\n",
        "        super(GINConv, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.mlp = mlp\n",
        "        self.bn = BatchNorm1d(dim_h)\n",
        "        self.edge_encoder = Linear(2, dim_h)\n",
        "    \n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        edge_attr = self.edge_encoder(edge_attr)\n",
        "        edge_index, _ = remove_self_loops(edge_index)\n",
        "        output = self.mlp(\n",
        "            self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
        "        )\n",
        "        return self.bn(output)\n",
        "    \n",
        "    def message(self, x_j, edge_attr):\n",
        "        return x_j + edge_attr\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        return aggr_out + x\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__"
      ],
      "metadata": {
        "id": "T0NfVLOlTSx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBwnEmwhVxwQ"
      },
      "source": [
        "### MLAP / DGI\n",
        "\n",
        "MLAP\n",
        "- see: [Multi-Level Attention Pooling for Graph Neural Networks - Unifying Graph Representations with Multiple Localities (2021) - Itoh, Kubo, Ikeda](https://arxiv.org/abs/2103.01488)\n",
        "\n",
        "\n",
        "DGI\n",
        "- see: [Deep Graph Infomax (2018) - Velickovic, Fedus, Hamilton, Lio, Bengio, Hjelm](https://arxiv.org/abs/1809.10341)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NDywjQj9VyVd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import Linear, Sequential, ReLU, ELU, Sigmoid\n",
        "\n",
        "from torch_geometric.nn.conv import GINConv\n",
        "from torch_geometric.nn.norm import GraphNorm\n",
        "from torch_geometric.nn.glob import AttentionalAggregation\n",
        "\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class DISC(torch.nn.Module):\n",
        "    def __init__(self, dim_h):\n",
        "        super(DISC, self).__init__()\n",
        "        W = torch.empty(dim_h, dim_h)\n",
        "        torch.nn.init.xavier_normal_(W)\n",
        "        self.W = torch.nn.Parameter(W)\n",
        "        self.W.requires_grad = True\n",
        "        self.sig = Sigmoid()\n",
        "    \n",
        "    def forward(self, h, s):\n",
        "        out = torch.matmul(self.W, s)\n",
        "        out = torch.matmul(h, out.unsqueeze(-1))\n",
        "        return self.sig(out)\n",
        "\n",
        "\n",
        "class MLAP_GIN(torch.nn.Module):\n",
        "    def __init__(self, dim_h, batch_size, depth, node_encoder, norm=False, residual=False, dropout=False):\n",
        "        super(MLAP_GIN, self).__init__()\n",
        "\n",
        "        self.dim_h = dim_h\n",
        "        self.batch_size = batch_size\n",
        "        self.depth = depth\n",
        "\n",
        "        self.node_encoder = node_encoder\n",
        "\n",
        "        self.norm = norm\n",
        "        self.residual = residual\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.loss_fn = torch.nn.BCELoss(reduction='sum')\n",
        "        self.discriminator = DISC(dim_h)\n",
        "\n",
        "        # non-linear projection function for cl task\n",
        "        self.projection = Sequential(\n",
        "            Linear(dim_h, int(dim_h/8)),\n",
        "            ELU(),\n",
        "            Linear(int(dim_h/8), dim_h)\n",
        "        )\n",
        "\n",
        "        # GIN layers\n",
        "        self.layers = torch.nn.ModuleList(\n",
        "            [GINConv(Sequential(\n",
        "                Linear(dim_h, dim_h),\n",
        "                ReLU(),\n",
        "                Linear(dim_h, dim_h))) for _ in range(depth)])\n",
        "            \n",
        "        # normalization layers\n",
        "        self.norm = torch.nn.ModuleList([GraphNorm(dim_h) for _ in range(self.depth)])\n",
        "        \n",
        "        # layer-wise attention poolings\n",
        "        self.att_poolings = torch.nn.ModuleList(\n",
        "            [\n",
        "                AttentionalAggregation(\n",
        "                Sequential(Linear(self.dim_h, 2*self.dim_h), \n",
        "                           ReLU(), \n",
        "                           Linear(2*self.dim_h, 1))) \n",
        "                for _ in range(depth)\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "    def contrastive_loss(self, g1_x, g2_x):\n",
        "        # compute projections + L2 row-wise normalizations\n",
        "        g1_projections = torch.nn.functional.normalize(\n",
        "            self.projection(g1_x), p=2, dim=1\n",
        "        )\n",
        "        g2_projections = torch.nn.functional.normalize(\n",
        "            self.projection(g2_x), p=2, dim=1\n",
        "        )\n",
        "        \n",
        "        g1_proj_T = torch.transpose(g1_projections, 0, 1)\n",
        "        g2_proj_T = torch.transpose(g2_projections, 0, 1)\n",
        "\n",
        "        inter_g1 = torch.exp(torch.matmul(g1_projections, g1_proj_T))\n",
        "        inter_g2 = torch.exp(torch.matmul(g2_projections, g2_proj_T))\n",
        "        intra_view = torch.exp(torch.matmul(g1_projections, g2_proj_T))\n",
        "\n",
        "        # main diagonal\n",
        "        corresponding_terms = torch.diagonal(intra_view, 0) \n",
        "        non_matching_intra = torch.diagonal(intra_view, -1).sum()\n",
        "        non_matching_inter_g1 = torch.diagonal(inter_g1, -1).sum()\n",
        "        non_matching_inter_g2 = torch.diagonal(inter_g2, -1).sum()\n",
        "\n",
        "        # inter-view pairs using g1\n",
        "        corresponding_terms_g1 = corresponding_terms / (\n",
        "            corresponding_terms + \n",
        "            non_matching_inter_g1 + \n",
        "            non_matching_intra\n",
        "        )\n",
        "        corresponding_terms_g1 = torch.log(corresponding_terms_g1)\n",
        "\n",
        "        # inter-view pairs using g2\n",
        "        corresponding_terms_g2 = corresponding_terms / (\n",
        "            corresponding_terms + \n",
        "            non_matching_inter_g2 + \n",
        "            non_matching_intra\n",
        "        )\n",
        "        corresponding_terms_g2 = torch.log(corresponding_terms_g2)\n",
        "\n",
        "        # contrasting terms of both divided by total nodes\n",
        "        loss = (\n",
        "            corresponding_terms_g1.sum() + \n",
        "            corresponding_terms_g2.sum()\n",
        "        ) / (\n",
        "            g1_x.shape[0] + \n",
        "            g2_x.shape[0]\n",
        "        )\n",
        "        \n",
        "        loss = loss / self.batch_size\n",
        "        return loss\n",
        "    \n",
        "    def layer_loop(self, x, edge_index, batch, cl=False, cl_all=False, dgi_task=False):\n",
        "        cl_embs = []\n",
        "        for d in range(self.depth):\n",
        "            x_in = x\n",
        "\n",
        "            # get node representation at layer d\n",
        "            x = self.layers[d](x, edge_index)\n",
        "            \n",
        "            if self.norm:\n",
        "                x = self.norm[d](x, batch)\n",
        "            \n",
        "            if d < self.depth - 1:\n",
        "                x = F.relu(x)\n",
        "            \n",
        "            if self.dropout:\n",
        "                x = F.dropout(x)\n",
        "            \n",
        "            if self.residual:\n",
        "                x = x + x_in\n",
        "\n",
        "            if not cl:\n",
        "                # use attention pooling for given depth\n",
        "                h_g = self.att_poolings[d](x, batch)\n",
        "                self.graph_embs.append(h_g)\n",
        "\n",
        "            if (\n",
        "                (cl and cl_all) or \n",
        "                (cl and (d == self.depth-1)) or \n",
        "                (dgi_task and (d == self.depth-1))\n",
        "            ):\n",
        "                # if using contrastive learning or DGI\n",
        "                cl_embs += [x]\n",
        "            \n",
        "        return cl_embs\n",
        "\n",
        "    def forward(self, batched_data, cl=False, cl_all=False, dgi_task=False):\n",
        "        self.graph_embs = []\n",
        "        # non-augmented graph\n",
        "        # note: populates self.graph_embs\n",
        "\n",
        "        node_depth = batched_data.node_depth\n",
        "        x_emb = self.node_encoder(batched_data.x, node_depth.view(-1,))\n",
        "        edge_index = batched_data.edge_index\n",
        "        batch = batched_data.batch\n",
        "\n",
        "        self.layer_loop(x_emb, edge_index, batch, dgi_task=dgi_task)\n",
        "\n",
        "        agg = self.aggregate()\n",
        "        self.graph_embs.append(agg)\n",
        "        output = torch.stack(self.graph_embs, dim=0)\n",
        "\n",
        "        # dgi task\n",
        "        dgi_loss = 0\n",
        "        if dgi_task:\n",
        "            # batch size // 5 to perform additional objectives\n",
        "            # only on 1/5th of the batch, for speed reasons\n",
        "            for i in range(self.batch_size // 5):\n",
        "                g = batched_data.get_example(i)\n",
        "\n",
        "                nd = g.node_depth\n",
        "                b = g.batch\n",
        "                \n",
        "                # contrastive pair\n",
        "                g1, g2 = self.get_contrastive_pair_from_batch(g, dgi_task=True)\n",
        "                g_diff_embs = self.layer_loop(g1, g2, b, dgi_task=True)[0]\n",
        "\n",
        "                g.x = self.node_encoder(g.x, nd.view(-1,).clone())\n",
        "                g_embs = self.layer_loop(g.x, g.edge_index, g.batch, dgi_task=True)[0]\n",
        "\n",
        "                # dgi objective on final_layer_embs, g_diff_embs, and output\n",
        "                agg = agg.clone()\n",
        "                positive = self.discriminator(g_embs, agg[i])\n",
        "                ones = torch.ones_like(positive)\n",
        "                negative = self.discriminator(g_diff_embs, agg[i])\n",
        "                zeros = torch.zeros_like(negative)\n",
        "\n",
        "                dgi_loss += (\n",
        "                    self.loss_fn(positive, ones) + self.loss_fn(negative, zeros)\n",
        "                ) / (positive.shape[0] + negative.shape[0])\n",
        "            \n",
        "            dgi_loss /= (self.batch_size // 5)\n",
        "\n",
        "        # contrastive learning task\n",
        "        cl_loss = 0\n",
        "        if cl:\n",
        "            for i in range(self.batch_size // 5):\n",
        "                g = batched_data.get_example(i)\n",
        "\n",
        "                # contrastive pair\n",
        "                g1, g2 = self.get_contrastive_pair_from_batch(g, dgi_task=False)\n",
        "                g1_embs = self.get_node_embedding(g.batch, g1, cl=True, cl_all=cl_all)\n",
        "                g2_embs = self.get_node_embedding(g.batch, g2, cl=True, cl_all=cl_all)\n",
        "\n",
        "                batch_cl_loss = 0\n",
        "                for j in range(len(g1_embs)):\n",
        "                    batch_cl_loss += self.contrastive_loss(g1_embs[j], g2_embs[j])\n",
        "                \n",
        "                batch_cl_loss = batch_cl_loss / len(g1_embs)\n",
        "                cl_loss += batch_cl_loss\n",
        "            \n",
        "            cl_loss /= (self.batch_size // 5)\n",
        "\n",
        "        return output, cl_loss, dgi_loss\n",
        "\n",
        "    def get_node_embedding(self, batch, g, cl, cl_all):\n",
        "        g_x, g_edge_index = g\n",
        "        return self.layer_loop(\n",
        "            g_x.clone(), \n",
        "            g_edge_index, \n",
        "            batch, \n",
        "            cl=cl, \n",
        "            cl_all=cl_all\n",
        "        )\n",
        "\n",
        "    def get_contrastive_pair_from_batch(self, g, dgi_task=False):\n",
        "        g_clone = g.clone()\n",
        "        nd = g.node_depth\n",
        "        # encode the nodes in the clone of g using given encoding network\n",
        "        g_clone.x = self.node_encoder(g_clone.x, nd.view(-1,).clone())\n",
        "\n",
        "        # create contrastive pairs from the input graph\n",
        "        return get_contrastive_graph_pair(g_clone, dgi_task=dgi_task)\n",
        "\n",
        "    def aggregate(self):\n",
        "        pass\n",
        "\n",
        "class MLAP_Sum(MLAP_GIN):\n",
        "    def aggregate(self):\n",
        "        return torch.stack(self.graph_embs, dim=0).sum(dim=0)\n",
        "\n",
        "class MLAP_Weighted(MLAP_GIN):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.weight = torch.nn.Parameter(torch.ones(self.depth, 1, 1))\n",
        "\n",
        "    def aggregate(self):\n",
        "        a = F.softmax(self.weight, dim=0)\n",
        "        h = torch.stack(self.graph_embs, dim=0)\n",
        "        return (a * h).sum(dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fnFG6_RV714"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7ft4PTPWV8eO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, batch_size, depth, dim_h, max_seq_len, node_encoder, vocab2idx, device):\n",
        "        super(Model, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.depth = depth\n",
        "        self.dim_h = dim_h\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.device = device\n",
        "\n",
        "        # token to idx lookup\n",
        "        self.vocab2idx = vocab2idx \n",
        "        \n",
        "        # architecture choices\n",
        "        self.node_encoder = node_encoder\n",
        "        self.gnn = MLAP_Weighted(\n",
        "            dim_h, batch_size, depth, \n",
        "            node_encoder, \n",
        "            norm=True, \n",
        "            residual=True, \n",
        "            dropout=True\n",
        "        )\n",
        "        self.decoder = LinearDecoder(\n",
        "            dim_h, max_seq_len, vocab2idx, device\n",
        "        )\n",
        "\n",
        "    def forward(self, batched_data, labels, training=False, cl=False, cl_all=False, dgi_task=False):\n",
        "        # GNN layer, contrastive work done here\n",
        "        embeddings, cl_loss, dgi_loss = self.gnn(\n",
        "            batched_data, \n",
        "            cl=cl, \n",
        "            cl_all=cl_all, \n",
        "            dgi_task=dgi_task\n",
        "        )\n",
        "\n",
        "        predictions = self.decoder(len(labels), embeddings, labels, training=training)\n",
        "\n",
        "        # for each batch, the prediction for the ith word is a logit\n",
        "        # decoding each prediction to a word is done in the evaluation task in main\n",
        "        return predictions, cl_loss, dgi_loss, embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAD and MADGap\n",
        "\n",
        "[Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View (2019) - Chen, Lin, Li, Li, Zhou, Sun](https://arxiv.org/abs/1909.03211)\n",
        "\n",
        ">We can observe that as the number of GNN layers increases, the MAD values become smaller. Apart from this, the MAD value of high-layer GNNs gets close to 0, which means that all the node representations become indistinguishable. GNN models update the node representation based on the features from neighboring nodes. We observe that the interaction between nodes makes their representations similar to each other. Similar phenomenons that the smoothness rises as the layer increases are also observed in other datasets as presented in Appendix B. Therefore, we conclude that smoothing is an essential nature for GNNs."
      ],
      "metadata": {
        "id": "i2nPyD6v3DEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import k_hop_subgraph\n",
        "import numpy as np\n",
        "\n",
        "def get_d(H):\n",
        "  \"\"\"\n",
        "  Pairwise Cosine Distance between nodes\n",
        "  \"\"\"\n",
        "  # asssuming row dimension are nodes\n",
        "  # column dim are hidden dimension\n",
        "  normed = torch.nn.functional.normalize(H, dim=1)\n",
        "  return (1 - normed @ normed.T)\n",
        "\n",
        "def get_mad(H, mask):\n",
        "  D = get_d(H)\n",
        "  n = torch.count_nonzero(D[mask])\n",
        "  return (D[mask].sum() / n).item()\n",
        "\n",
        "def get_mad_global(H):\n",
        "  # MAD: mean average distance\n",
        "  D = get_d(H)\n",
        "  return D.mean().item()\n",
        "\n",
        "def get_all_node_ids(num_nodes):\n",
        "  return torch.linspace(0, num_nodes - 1, steps=num_nodes, dtype=int)\n",
        "\n",
        "def get_mad_gap(node_id, embedding, data):\n",
        "  # MADgap\n",
        "  # find nodes that are 3 or fewer edges away for MAD_neb\n",
        "  neb, _, _, _ = k_hop_subgraph(node_id, 3, data.edge_index)\n",
        "  mad_neb = get_mad(embedding, neb)\n",
        "  \n",
        "  # find nodes that are 8 or more edges away for MAD_rmt\n",
        "  subset, _, _, _ = k_hop_subgraph(node_id, 7, data.edge_index)\n",
        "  \n",
        "  # get compliment of nodes within 7 steps of node_id\n",
        "  num_nodes = data.x.shape[0]\n",
        "  all_node_ids = get_all_node_ids(num_nodes)\n",
        "  mask = torch.ones_like(all_node_ids, dtype=bool)\n",
        "  mask[subset] = 0\n",
        "  rmt = all_node_ids[mask]\n",
        "\n",
        "  mad_rmt = get_mad(embedding, rmt)\n",
        "\n",
        "  return (mad_rmt - mad_neb)\n",
        "\n",
        "def randomly_sample_node_ids(num_samples, data):\n",
        "    num_nodes = data.x.shape[0]\n",
        "    all_node_ids = get_all_node_ids(num_nodes)\n",
        "    bool_mask = np.zeros_like(all_node_ids, dtype=bool)\n",
        "    bool_mask[:num_samples] = True\n",
        "    np.random.shuffle(bool_mask)\n",
        "    return all_node_ids[bool_mask]\n",
        "\n",
        "def get_sampled_mad_gap(num_samples, data, embedding):\n",
        "  \"\"\"\n",
        "  According to our assumption, large MADGap value indicates that the \n",
        "  useful information received by the node is more than noise. ...\n",
        "  On the contrary, small or negative MADGap means over-smoothing and \n",
        "  inferior performance. - Chen, Lin, Li, et. al (2019) pp. 4\n",
        "  \"\"\"\n",
        "  random_sample = randomly_sample_node_ids(num_samples, data)\n",
        "  mad_gaps = []\n",
        "  for node_id in random_sample:\n",
        "    mad_gaps.append(get_mad_gap(node_id.item(), embedding, data))\n",
        "  return np.array(mad_gaps).mean()\n",
        "\n",
        "def get_global_mad_gap(data, embedding, perc_to_sample=1.0):\n",
        "  \"\"\"\n",
        "  Makes more sense for larger graphs. In the AST task, graphs are relatively\n",
        "  small... but are also tree-like. \n",
        "  \"\"\"\n",
        "  num_samples = int(data.x.shape[0] * perc_to_sample)\n",
        "  return get_sampled_mad_gap(num_samples, data, embedding)"
      ],
      "metadata": {
        "id": "oNHMj22e2_jS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iErB7DcYCXm",
        "outputId": "53f22259-e88d-4ef3-ebfc-ac72e1e0e4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘checkpoints’: File exists\n"
          ]
        }
      ],
      "source": [
        "!cd $nb_path_bash && mkdir \"checkpoints\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwGxp_PRWAMt"
      },
      "source": [
        "### Main\n",
        "\n",
        "Model configuration and training loop."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_tag(alpha, cl, cl_all, dgi_task, depth):\n",
        "  return f\"alpha__{alpha}_cl__{cl}_cl_all__{cl_all}_dgi_task__{dgi_task}_depth__{depth}\"\n",
        "\n",
        "def randomly_mask(dataset, size):\n",
        "  bool_mask = np.zeros(len(dataset), dtype=bool)\n",
        "  bool_mask[:size] = True\n",
        "  np.random.shuffle(bool_mask)\n",
        "  out = dataset[bool_mask]\n",
        "  return out"
      ],
      "metadata": {
        "id": "i_qjQrjlCqTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "mh7dpE0hWAx3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
        "\n",
        "\n",
        "def train(\n",
        "      model, \n",
        "      device, \n",
        "      loader, \n",
        "      optimizer, \n",
        "      scheduler, \n",
        "      multicls_criterion, \n",
        "      epoch, \n",
        "      alpha=0.05, \n",
        "      cl=False, \n",
        "      cl_all=False, \n",
        "      dgi_task=False,\n",
        "      eval_hook=lambda x: x,\n",
        "      save_checkpoint_every_n_step=35,\n",
        "      csv_f_name=\"\",\n",
        "    ):\n",
        "    if cl and dgi_task:\n",
        "        # check settings\n",
        "        raise Exception(\"Cannot use both a contrastive and dgi loss term\\n\")\n",
        "\n",
        "    # setup recording and checkpoints\n",
        "    tag = get_training_tag(alpha, cl, cl_all, dgi_task, model.depth)\n",
        "    chkpt_folder = nb_path + f'/checkpoints/{tag}__epoch_{epoch}'\n",
        "    if not os.path.exists(chkpt_folder):\n",
        "        os.mkdir(chkpt_folder)\n",
        "\n",
        "    # total loss for this epoch\n",
        "    loss_accum = 0\n",
        "    for step, batch in enumerate(loader):\n",
        "        avg_loss = loss_accum / (step + 1)\n",
        "        # run eval if requested\n",
        "        e = eval_hook(step)\n",
        "        if e:\n",
        "          # unpack the metrics if evaluation ran\n",
        "          (\n",
        "            train_perf, \n",
        "            valid_perf, \n",
        "            test_perf, \n",
        "            mad_global_train, \n",
        "            mad_global_valid, \n",
        "            mad_global_test\n",
        "          ) = e\n",
        "\n",
        "          # append it to the csv record for this model\n",
        "          with open(csv_f_name, 'a') as record:\n",
        "            writer = csv.writer(record)\n",
        "            writer.writerow(\n",
        "                [\n",
        "                    alpha,\n",
        "                    cl,\n",
        "                    cl_all,\n",
        "                    dgi_task,\n",
        "                    epoch, \n",
        "                    step, \n",
        "                    avg_loss, \n",
        "                    cl_loss if isinstance(cl_loss, int) else cl_loss.item(), \n",
        "                    train_perf[dataset.eval_metric], \n",
        "                    valid_perf[dataset.eval_metric],\n",
        "                    test_perf[dataset.eval_metric],\n",
        "                    mad_global_train.mean(),\n",
        "                    mad_global_valid.mean(),\n",
        "                    mad_global_test.mean()\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        # --- train the model ---\n",
        "        batch = batch.to(device)\n",
        "        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
        "            pass\n",
        "        else:\n",
        "            # train\n",
        "            labels = [batch.y[i] for i in range(len(batch.y))]\n",
        "            pred_list, cl_loss, dgi_loss, embeddings = model(\n",
        "                batch, labels, training=True,\n",
        "                cl=cl, \n",
        "                cl_all=cl_all, \n",
        "                dgi_task=dgi_task\n",
        "            )\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # loss + update\n",
        "            loss = 0\n",
        "            for i in range(len(pred_list)):\n",
        "                loss += (1-alpha) * multicls_criterion(\n",
        "                    pred_list[i].to(torch.float32), \n",
        "                    batch.y_arr[:, i]\n",
        "                )\n",
        "\n",
        "            loss /= len(pred_list)\n",
        "            if cl:\n",
        "                loss -= alpha * cl_loss\n",
        "            if dgi_task:\n",
        "                loss -= alpha * dgi_loss\n",
        "\n",
        "            with torch.autograd.set_detect_anomaly(True):\n",
        "                loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # report loss after nth batch\n",
        "            loss_accum += loss.item()\n",
        "            print(\n",
        "                f'\\rAverage loss after batch {step}: {avg_loss:.4f}. Contrastive Term: {cl_loss:.3f}', \n",
        "                end=''\n",
        "            )\n",
        "        \n",
        "        # --- checkpoints ---\n",
        "        if (\n",
        "            (step+1) % save_checkpoint_every_n_step == 0 or \n",
        "            step == len(loader)-1\n",
        "          ): \n",
        "            # save model after every n batches\n",
        "            print(f\"\\nCheckpoint saved here: {chkpt_folder}\")\n",
        "            step_name = str((step+1) // save_checkpoint_every_n_step)\n",
        "            checkpoint_f_name = chkpt_folder + '/model' + step_name + '.pt'\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "            }, checkpoint_f_name)\n",
        "\n",
        "            with open(f\"{chkpt_folder}/model{step_name}_metrics.txt\", \"w\") as f:\n",
        "              # just for reference save associated metrics\n",
        "              f.write(f\"Avg Loss: {avg_loss:.15f}\\n\")\n",
        "              f.write(f\"Contrastive Term: {cl_loss:.15f}\")\n",
        "\n",
        "    # end of this epoch\n",
        "    print(f'Average training loss: {avg_loss}')\n",
        "    return avg_loss, checkpoint_f_name\n",
        "\n",
        "def eval(model, device, loader, evaluator, arr_to_seq):\n",
        "    \"\"\"\n",
        "    Use official OGB evaluator to test results of model output\n",
        "    \"\"\"\n",
        "    seq_ref_list = []\n",
        "    seq_pred_list = []\n",
        "    mad_values = []\n",
        "    for step, batch in enumerate(loader):\n",
        "        batch = batch.to(device)\n",
        "        if batch.x.shape[0] == 1:\n",
        "            pass\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                labels = [batch.y[i] for i in range(len(batch.y))]\n",
        "                # no cl by default\n",
        "                pred_list, _, _, embeddings = model(batch, labels) \n",
        "\n",
        "            mat = []\n",
        "            for i in range(len(pred_list)):\n",
        "                # get model's predictions\n",
        "                mat.append(torch.argmax(pred_list[i], dim=1).view(-1, 1))\n",
        "            \n",
        "            # embeddings are stacked batchwise along the \n",
        "            # row dimension. Take the embeddings of the final\n",
        "            # batch, or take the mean of all embeddings along the 0th dim\n",
        "            mad_global = get_mad_global(embeddings[-1])\n",
        "            \n",
        "            # save for eval\n",
        "            seq_ref_list.extend(labels)\n",
        "            mat = torch.cat(mat, dim=1)\n",
        "            seq_pred = [arr_to_seq(arr) for arr in mat]\n",
        "            seq_pred_list.extend(seq_pred)\n",
        "            mad_values.append(mad_global)\n",
        "\n",
        "    input_dict = {\"seq_ref\": seq_ref_list, \"seq_pred\": seq_pred_list}\n",
        "    return evaluator.eval(input_dict), np.array(mad_values)\n",
        "\n",
        "def main(\n",
        "      starting_chkpt=None, \n",
        "      cl=False, \n",
        "      cl_all=False, \n",
        "      dgi_task=False, \n",
        "      run_eval_every_n_batches=None, \n",
        "      # CL hyperparameter\n",
        "      alpha=0.05,\n",
        "      num_epochs=50,\n",
        "      save_checkpoint_every_n_step=35\n",
        "  ):\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # model & training conf\n",
        "    depth = 3\n",
        "    epochs = num_epochs\n",
        "    learning_rate = 0.001\n",
        "    step_size = 10\n",
        "    decay_rate = 0.1\n",
        "    weight_decay = 0.00005\n",
        "    dim_h = 512\n",
        "\n",
        "    # model initialization\n",
        "    node_encoder = ASTNodeEncoder(\n",
        "        dim_h, \n",
        "        num_nodetypes=len(nodetypes_mapping['type']), \n",
        "        num_nodeattributes=len(nodeattributes_mapping['attr']), \n",
        "        max_depth=20\n",
        "    )\n",
        "    model = Model(\n",
        "        batch_size, \n",
        "        depth, \n",
        "        dim_h, \n",
        "        max_seq_len, \n",
        "        node_encoder, \n",
        "        vocab2idx, \n",
        "        DEVICE\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    num_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f'Model # Params: {num_params}')\n",
        "    print(\"-------------\\n\\n\\n\")\n",
        "\n",
        "    # training configuration\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=decay_rate)\n",
        "    multicls_criterion = torch.nn.CrossEntropyLoss()\n",
        "    starting_epoch = 1\n",
        "\n",
        "    if starting_chkpt:\n",
        "        checkpoint = torch.load(starting_chkpt)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        starting_epoch = checkpoint['epoch']\n",
        "\n",
        "    valid_curve = []\n",
        "    test_curve = []\n",
        "    train_curve = []\n",
        "    trainL_curve = []\n",
        "    train_mad_curve = []\n",
        "    test_mad_curve = []\n",
        "    valid_mad_curve = []\n",
        "\n",
        "    # create a csv for recording\n",
        "    tag = get_training_tag(alpha, cl, cl_all, dgi_task, model.depth)\n",
        "    csv_f_name = f'{nb_path}/checkpoints/{tag}.csv'\n",
        "    with open(csv_f_name, 'w') as record:\n",
        "      writer = csv.writer(record)\n",
        "      writer.writerow(\n",
        "          [\n",
        "              \"Alpha\",\n",
        "              \"CL\",\n",
        "              \"CL All\",\n",
        "              \"DGI\",\n",
        "              \"Epoch\", \n",
        "              \"Batch\", \n",
        "              \"Avg Loss\", \n",
        "              \"Contrastive Term\", \n",
        "              \"Train Performance\", \n",
        "              \"Validation Performance\",\n",
        "              \"Test Performance\",\n",
        "              \"Train MAD Global Average\",\n",
        "              \"Validation MAD Global Average\",\n",
        "              \"Test MAD Global Average\"\n",
        "          ]\n",
        "      )\n",
        "\n",
        "    def eval_hook():\n",
        "      print('\\n\\nEvaluating...')\n",
        "      train_perf, mad_global_train = eval(\n",
        "          model, DEVICE, train_loader, evaluator, \n",
        "          arr_to_seq=lambda arr: decode_arr_to_seq(arr, idx2vocab)\n",
        "      )\n",
        "      valid_perf, mad_global_valid = eval(\n",
        "          model, DEVICE, valid_loader, evaluator, \n",
        "          arr_to_seq=lambda arr: decode_arr_to_seq(arr, idx2vocab)\n",
        "      )\n",
        "      test_perf, mad_global_test = eval(\n",
        "          model, DEVICE, test_loader, evaluator, \n",
        "          arr_to_seq=lambda arr: decode_arr_to_seq(arr, idx2vocab)\n",
        "      )\n",
        "\n",
        "      print(\"Eval Criteria:\")\n",
        "      print(\n",
        "          '\\tTrain:', train_perf[dataset.eval_metric],\n",
        "          'Validation:', valid_perf[dataset.eval_metric],\n",
        "          'Test:', test_perf[dataset.eval_metric]\n",
        "      )\n",
        "      print(\"MAD global batch averages\")\n",
        "      print(\n",
        "          '\\tTrain:', mad_global_train.mean(),\n",
        "          'Validation:', mad_global_valid.mean(),\n",
        "          'Test:', mad_global_test.mean()\n",
        "      )\n",
        "      \n",
        "      return (\n",
        "          train_perf, \n",
        "          valid_perf, \n",
        "          test_perf, \n",
        "          mad_global_train, \n",
        "          mad_global_valid, \n",
        "          mad_global_test\n",
        "      )\n",
        "\n",
        "\n",
        "    for epoch in range(starting_epoch, epochs + 1):\n",
        "        print(f\"Training epoch: {epoch}/{epochs+1}\")\n",
        "        \n",
        "        # training model\n",
        "        train_loss, latest_checkpoint_path = train(\n",
        "            model, \n",
        "            DEVICE, \n",
        "            train_loader, \n",
        "            optimizer, \n",
        "            scheduler, \n",
        "            multicls_criterion, \n",
        "            epoch, \n",
        "            cl=cl, \n",
        "            alpha=alpha,\n",
        "            cl_all=cl_all, \n",
        "            dgi_task=dgi_task,\n",
        "            # run evaluation every n batches\n",
        "            eval_hook=lambda x: (\n",
        "                eval_hook() \n",
        "                  if run_eval_every_n_batches is not None and \n",
        "                  (x != 0 and x % run_eval_every_n_batches == 0) \n",
        "                else None\n",
        "            ),\n",
        "            save_checkpoint_every_n_step=save_checkpoint_every_n_step,\n",
        "            csv_f_name=csv_f_name\n",
        "        )\n",
        "        scheduler.step()\n",
        "\n",
        "        # run evaluation after each epoch\n",
        "        (\n",
        "            train_perf, \n",
        "            valid_perf, \n",
        "            test_perf, \n",
        "            mad_global_train, \n",
        "            mad_global_valid, \n",
        "            mad_global_test\n",
        "        ) = eval_hook()\n",
        "\n",
        "        print(f\"Train Loss: {train_loss}\")\n",
        "\n",
        "        train_curve.append(train_perf[dataset.eval_metric])\n",
        "        valid_curve.append(valid_perf[dataset.eval_metric])\n",
        "        test_curve.append(test_perf[dataset.eval_metric])\n",
        "        trainL_curve.append(train_loss)\n",
        "        train_mad_curve.append(mad_global_train.mean())\n",
        "        test_mad_curve.append(mad_global_valid.mean())\n",
        "        valid_mad_curve.append(mad_global_test.mean())\n",
        "\n",
        "    print('\\n\\n\\nFinished training!')\n",
        "    print('F1')\n",
        "    best_val_epoch = np.argmax(np.array(valid_curve))\n",
        "    best_train = max(train_curve)\n",
        "    print('Best validation score: {}'.format(valid_curve[best_val_epoch]))\n",
        "    print('Test score: {}'.format(test_curve[best_val_epoch]))\n",
        "    print('Finished test: {}, Validation: {}, Train: {}, epoch: {}, best train: {}, best loss: {}'\n",
        "          .format(\n",
        "              test_curve[best_val_epoch], \n",
        "              valid_curve[best_val_epoch], \n",
        "              train_curve[best_val_epoch],\n",
        "              best_val_epoch, \n",
        "              best_train, \n",
        "              min(trainL_curve)\n",
        "          )\n",
        "    )\n",
        "\n",
        "    # return everything about this training\n",
        "    return (\n",
        "        csv_f_name, \n",
        "        latest_checkpoint_path,\n",
        "        train_curve,\n",
        "        valid_curve,\n",
        "        test_curve,\n",
        "        trainL_curve,\n",
        "        train_mad_curve,\n",
        "        test_mad_curve,\n",
        "        valid_mad_curve\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmenm81UkSeJ",
        "outputId": "2e8a8ec5-8744-4d0f-ba68-28e1398d14fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/graphproppred/code2.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.91 GB: 100%|██████████| 934/934 [00:52<00:00, 17.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/code2.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 452741/452741 [00:01<00:00, 330107.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into PyG objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 452741/452741 [00:21<00:00, 20835.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n",
            "/usr/local/lib/python3.9/dist-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage of top 5000 vocabulary:\n",
            "0.9025832389087423\n"
          ]
        }
      ],
      "source": [
        "num_vocab = 5000\n",
        "max_seq_len = 5\n",
        "batch_size = 50\n",
        "\n",
        "# dataset objects\n",
        "# best to load these only once in colab\n",
        "# otherwise, memory never freed and runtime crashes\n",
        "dataset_name = \"ogbg-code2\"\n",
        "dataset = PygGraphPropPredDataset(dataset_name)\n",
        "evaluator = Evaluator(dataset_name)\n",
        "\n",
        "split_idx = dataset.get_idx_split()\n",
        "vocab2idx, idx2vocab = get_vocab_mapping([dataset.data.y[i] for i in split_idx['train']], num_vocab)\n",
        "dataset.transform = transforms.Compose([augment_edge, lambda data: encode_y_to_arr(data, vocab2idx, max_seq_len)])\n",
        "\n",
        "nodetypes_mapping = pd.read_csv(os.path.join(dataset.root, 'mapping', 'typeidx2type.csv.gz'))\n",
        "nodeattributes_mapping = pd.read_csv(os.path.join(dataset.root, 'mapping', 'attridx2attr.csv.gz'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EoDIrwXl9UUY"
      },
      "outputs": [],
      "source": [
        "full_training = randomly_mask(dataset[split_idx[\"train\"]], batch_size * 800)\n",
        "full_valid = randomly_mask(dataset[split_idx[\"valid\"]], batch_size * 800)\n",
        "full_test = randomly_mask(dataset[split_idx[\"test\"]], batch_size * 800)\n",
        "\n",
        "train_loader = DataLoader(full_training, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(full_valid, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(full_test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def generate_result_presentation(csv_f_name):\n",
        "  # load the csv\n",
        "  train_details = pd.read_csv(csv_f_name)\n",
        "\n",
        "  # placeholder title for now\n",
        "  plt.figure(figsize=(40,10))\n",
        "\n",
        "  plt.subplot(1, 3, 1)\n",
        "  plt.title(csv_f_name.split(\"/\")[-1].split(\".csv\")[0])\n",
        "  plt.xlabel('Recording (every n batches)')\n",
        "  plt.xticks(range(1, train_details.shape[0]))\n",
        "  plt.ylabel('F1 Score')\n",
        "  plt.plot(train_details['Train Performance'], label = 'Train Performance')\n",
        "  plt.plot(train_details['Test Performance'], label = 'Test Performance')\n",
        "  plt.plot(train_details['Validation Performance'], label = 'Validation Performance')\n",
        "  plt.legend()\n",
        "  plt.plot()\n",
        "\n",
        "  plt.subplot(1, 3, 2)\n",
        "  plt.title(csv_f_name.split(\"/\")[-1].split(\".csv\")[0])\n",
        "  plt.xlabel('Recording (every n batches)')\n",
        "  plt.xticks(range(1, train_details.shape[0]))\n",
        "  plt.ylabel('Batchwise MAD')\n",
        "  plt.plot(train_details['Train MAD Global Average'], label = 'Train MAD Global Average')\n",
        "  plt.plot(train_details['Test MAD Global Average'], label = 'Test MAD Global Average')\n",
        "  plt.plot(train_details['Validation MAD Global Average'], label = 'Validation MAD Global Average')\n",
        "  plt.legend()\n",
        "  plt.plot()\n",
        "\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.title(csv_f_name.split(\"/\")[-1].split(\".csv\")[0])\n",
        "  plt.xlabel('Recording (every n batches)')\n",
        "  plt.xticks(range(1, train_details.shape[0]))\n",
        "  plt.ylabel('Cross Entropy Loss')\n",
        "  plt.plot(train_details['Avg Loss'], label = 'Train Loss')\n",
        "  plt.plot(train_details['Contrastive Term'], label = 'Train Loss Contrastive Term')\n",
        "  plt.legend()\n",
        "  plt.plot()\n",
        "\n",
        "  # print the table\n",
        "  train_details"
      ],
      "metadata": {
        "id": "jba_Lx_uZ-Dd"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_epochs = 5\n",
        "model_configs = [\n",
        "  # No CL\n",
        "  {\"alpha\": 0.0, \"cl\": False, \"cl_all\": False, \"dgi_task\": False, \"run_eval_every_n_batches\": 50, \"num_epochs\": all_epochs, \"save_checkpoint_every_n_step\": 300},\n",
        "  # CL 1 layer, ablating alpha\n",
        "  {\"alpha\": 0.05, \"cl\": True, \"cl_all\": False, \"dgi_task\": False, \"run_eval_every_n_batches\": 50, \"num_epochs\": all_epochs, \"save_checkpoint_every_n_step\": 300},\n",
        "  {\"alpha\": 0.10, \"cl\": True, \"cl_all\": False, \"dgi_task\": False, \"run_eval_every_n_batches\": 50, \"num_epochs\": all_epochs, \"save_checkpoint_every_n_step\": 300},\n",
        "  {\"alpha\": 0.15, \"cl\": True, \"cl_all\": False, \"dgi_task\": False, \"run_eval_every_n_batches\": 50, \"num_epochs\": all_epochs, \"save_checkpoint_every_n_step\": 300},\n",
        "  {\"alpha\": 0.20, \"cl\": True, \"cl_all\": False, \"dgi_task\": False, \"run_eval_every_n_batches\": 50, \"num_epochs\": all_epochs, \"save_checkpoint_every_n_step\": 300},\n",
        "  # CL all layers, ablating alpha\n",
        "  {\"alpha\": 0.05, \"cl\": False, \"cl_all\": True, \"dgi_task\": False, \"run_eval_every_n_batches\": 50, \"num_epochs\": all_epochs, \"save_checkpoint_every_n_step\": 300},\n",
        "  {\"alpha\": 0.10, \"cl\": False, \"cl_all\": True, \"dgi_task\": False, \"run_eval_every_n_batches\": 50, \"num_epochs\": all_epochs, \"save_checkpoint_every_n_step\": 300},\n",
        "  {\"alpha\": 0.15, \"cl\": False, \"cl_all\": True, \"dgi_task\": False, \"run_eval_every_n_batches\": 50, \"num_epochs\": all_epochs, \"save_checkpoint_every_n_step\": 300},\n",
        "  {\"alpha\": 0.20, \"cl\": False, \"cl_all\": True, \"dgi_task\": False, \"run_eval_every_n_batches\": 50, \"num_epochs\": all_epochs, \"save_checkpoint_every_n_step\": 300},\n",
        "]"
      ],
      "metadata": {
        "id": "Lf44lVYfY2KN"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conf in model_configs:\n",
        "  print(conf)\n",
        "  (\n",
        "    csv_f_name, \n",
        "    latest_checkpoint_path,\n",
        "    train_curve,\n",
        "    valid_curve,\n",
        "    test_curve,\n",
        "    trainL_curve,\n",
        "    train_mad_curve,\n",
        "    test_mad_curve,\n",
        "    valid_mad_curve\n",
        "  ) = main(**conf)\n",
        "  generate_result_presentation(csv_f_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig1WfVU5Z0XL",
        "outputId": "9140f192-355b-40a9-c937-e00afebca4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpha': 0.0, 'cl': False, 'cl_all': False, 'dgi_task': False, 'run_eval_every_n_batches': 50, 'num_epochs': 5, 'save_checkpoint_every_n_step': 300}\n",
            "Model # Params: 23612920\n",
            "-------------\n",
            "\n",
            "\n",
            "\n",
            "Training epoch: 1/6\n",
            "Average loss after batch 49: 3.7074. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06594954781329782 Validation: 0.0626472116654875 Test: 0.05936926280693367\n",
            "MAD global batch averages\n",
            "\tTrain: 0.06568942429497839 Validation: 0.06387253718642229 Test: 0.06381457131822722\n",
            "Average loss after batch 99: 3.5751. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06708788114663115 Validation: 0.06382834853711832 Test: 0.06081825045739753\n",
            "MAD global batch averages\n",
            "\tTrain: 0.056347987605258824 Validation: 0.053829292499784305 Test: 0.05325369651435719\n",
            "Average loss after batch 149: 3.4952. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06709621447996446 Validation: 0.06385026202267732 Test: 0.060836475352604384\n",
            "MAD global batch averages\n",
            "\tTrain: 0.06990993809886277 Validation: 0.06616638293102611 Test: 0.06619850297061756\n",
            "Average loss after batch 199: 3.4463. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06707871447996448 Validation: 0.06382104404193198 Test: 0.060836475352604384\n",
            "MAD global batch averages\n",
            "\tTrain: 0.07784276272170246 Validation: 0.0738983010543058 Test: 0.07388180668268497\n",
            "Average loss after batch 249: 3.4207. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.0582952620990121 Validation: 0.055589051883481476 Test: 0.05323372888982512\n",
            "MAD global batch averages\n",
            "\tTrain: 0.1122322260402143 Validation: 0.10486698935635763 Test: 0.10503322329872833\n",
            "Average loss after batch 299: 3.4082. Contrastive Term: 0.000\n",
            "Checkpoint saved here: drive/MyDrive/Colab Notebooks/venv_MLAP_test_eval/checkpoints/alpha__0.0_cl__False_cl_all__False_dgi_task__False_depth__3__epoch_1\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.05284990495615496 Validation: 0.04987109305161634 Test: 0.0482043448623547\n",
            "MAD global batch averages\n",
            "\tTrain: 0.10637618999928236 Validation: 0.10022399854933929 Test: 0.09948588864440798\n",
            "Average loss after batch 349: 3.3964. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.039982617798867796 Validation: 0.03586420178215769 Test: 0.037465940090325\n",
            "MAD global batch averages\n",
            "\tTrain: 0.14257465412840248 Validation: 0.1279711557116107 Test: 0.12710340192079\n",
            "Average loss after batch 399: 3.3859. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.061198893051393054 Validation: 0.05645007794939863 Test: 0.05432975383768166\n",
            "MAD global batch averages\n",
            "\tTrain: 0.16070633749477564 Validation: 0.15000031661869923 Test: 0.14880263846121508\n",
            "Average loss after batch 449: 3.3680. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06678753996003996 Validation: 0.06328698109387945 Test: 0.06065878262433756\n",
            "MAD global batch averages\n",
            "\tTrain: 0.17741753919050096 Validation: 0.1588622839465183 Test: 0.15804670647567387\n",
            "Average loss after batch 499: 3.3516. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06779444860694861 Validation: 0.06389408899379535 Test: 0.061443574093929476\n",
            "MAD global batch averages\n",
            "\tTrain: 0.20888708570972084 Validation: 0.19340981896844422 Test: 0.19521034172903703\n",
            "Average loss after batch 549: 3.3409. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06700063908313907 Validation: 0.06032755063959868 Test: 0.05905094186942191\n",
            "MAD global batch averages\n",
            "\tTrain: 0.2651040809415281 Validation: 0.2456099240015581 Test: 0.24822973585549682\n",
            "Average loss after batch 599: 3.3300. Contrastive Term: 0.000\n",
            "Checkpoint saved here: drive/MyDrive/Colab Notebooks/venv_MLAP_test_eval/checkpoints/alpha__0.0_cl__False_cl_all__False_dgi_task__False_depth__3__epoch_1\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.0666443494005994 Validation: 0.06002249784517392 Test: 0.0589231144794294\n",
            "MAD global batch averages\n",
            "\tTrain: 0.23945788377895952 Validation: 0.22115617416619732 Test: 0.21885848135299182\n",
            "Average loss after batch 649: 3.3166. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06496490911865911 Validation: 0.05949744377451789 Test: 0.05815929610352793\n",
            "MAD global batch averages\n",
            "\tTrain: 0.29606565464288 Validation: 0.26767357350765225 Test: 0.2694285579348208\n",
            "Average loss after batch 699: 3.3080. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.050494990287490285 Validation: 0.04514247907989417 Test: 0.04598825480454785\n",
            "MAD global batch averages\n",
            "\tTrain: 0.2740374117344618 Validation: 0.24695014658524642 Test: 0.2464212505210505\n",
            "Average loss after batch 749: 3.3001. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06070966060899884 Validation: 0.05386766063454497 Test: 0.052865335512957155\n",
            "MAD global batch averages\n",
            "\tTrain: 0.3712712637707591 Validation: 0.336864309511769 Test: 0.3377639148596479\n",
            "Average loss after batch 799: 3.2902. Contrastive Term: 0.000\n",
            "Checkpoint saved here: drive/MyDrive/Colab Notebooks/venv_MLAP_test_eval/checkpoints/alpha__0.0_cl__False_cl_all__False_dgi_task__False_depth__3__epoch_1\n",
            "Average training loss: 3.2901523262262344\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06616876012876013 Validation: 0.060104902669657026 Test: 0.05954767874532774\n",
            "MAD global batch averages\n",
            "\tTrain: 0.3002382563985884 Validation: 0.26819776830057607 Test: 0.26708774723468987\n",
            "Train Loss: 3.2901523262262344\n",
            "Training epoch: 2/6\n",
            "Average loss after batch 49: 2.9413. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06275226565101565 Validation: 0.054997602797488845 Test: 0.05595076030423214\n",
            "MAD global batch averages\n",
            "\tTrain: 0.41363319631665946 Validation: 0.36027165327865135 Test: 0.36209969449966534\n",
            "Average loss after batch 99: 2.9958. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.058747068764568755 Validation: 0.05136914698864123 Test: 0.05284537491344489\n",
            "MAD global batch averages\n",
            "\tTrain: 0.447155534029007 Validation: 0.39485832207573324 Test: 0.3987990201266317\n",
            "Average loss after batch 149: 3.0009. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06650570276129097 Validation: 0.06044773013918826 Test: 0.05854137458839481\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4410752232372761 Validation: 0.3870721043982182 Test: 0.38893123117014594\n",
            "Average loss after batch 199: 3.0316. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.0728069848901099 Validation: 0.06461004335834505 Test: 0.06473063973063972\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4503307943418622 Validation: 0.39526201853084353 Test: 0.3938435633796223\n",
            "Average loss after batch 249: 3.0356. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06499131715506716 Validation: 0.05923667329636562 Test: 0.05823371442562257\n",
            "MAD global batch averages\n",
            "\tTrain: 0.40942492093890903 Validation: 0.3629042045814464 Test: 0.3606825405413578\n",
            "Average loss after batch 299: 3.0306. Contrastive Term: 0.000\n",
            "Checkpoint saved here: drive/MyDrive/Colab Notebooks/venv_MLAP_test_eval/checkpoints/alpha__0.0_cl__False_cl_all__False_dgi_task__False_depth__3__epoch_2\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.0672210019147519 Validation: 0.060877234456144916 Test: 0.06039872612453257\n",
            "MAD global batch averages\n",
            "\tTrain: 0.46478341810405255 Validation: 0.41137332359993223 Test: 0.4078084869577564\n",
            "Average loss after batch 349: 3.0376. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06616980241980241 Validation: 0.057957728917977853 Test: 0.058386176982404434\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4422629426047206 Validation: 0.39230230372374636 Test: 0.3913461386410685\n",
            "Average loss after batch 399: 3.0398. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06747548493173493 Validation: 0.057153712697824544 Test: 0.05892406122723236\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4253096468001604 Validation: 0.37517519909847746 Test: 0.3718158619686248\n",
            "Average loss after batch 449: 3.0287. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06744555139305139 Validation: 0.05971859922423099 Test: 0.06000240697479626\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4736532247066498 Validation: 0.4170626412987448 Test: 0.4164969115974148\n",
            "Average loss after batch 499: 3.0242. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.060308696719946715 Validation: 0.05146799799471053 Test: 0.05351502146882136\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4228708678483963 Validation: 0.37126811057394393 Test: 0.37228804066403853\n",
            "Average loss after batch 549: 3.0232. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06919391428016428 Validation: 0.060665227017069945 Test: 0.0606572342972015\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4435035954788327 Validation: 0.3932212046643055 Test: 0.3899305565006912\n",
            "Average loss after batch 599: 3.0226. Contrastive Term: 0.000\n",
            "Checkpoint saved here: drive/MyDrive/Colab Notebooks/venv_MLAP_test_eval/checkpoints/alpha__0.0_cl__False_cl_all__False_dgi_task__False_depth__3__epoch_2\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06636595533551415 Validation: 0.0589339604700958 Test: 0.059228858135364416\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4603657117113471 Validation: 0.4058714430102634 Test: 0.4081396461551445\n",
            "Average loss after batch 649: 3.0236. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.07121087892499657 Validation: 0.06318556244707799 Test: 0.0629309346162818\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4778317529708147 Validation: 0.4193259835634503 Test: 0.4205991390897364\n",
            "Average loss after batch 699: 3.0228. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.07280696706071706 Validation: 0.06471118373866323 Test: 0.06324859809004149\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4721602839976549 Validation: 0.41245517679194654 Test: 0.41455123232410274\n",
            "Average loss after batch 749: 3.0269. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.07048370497557997 Validation: 0.06279594510080551 Test: 0.06241177165179352\n",
            "MAD global batch averages\n",
            "\tTrain: 0.4582635207846761 Validation: 0.40162220845076396 Test: 0.4035272426173464\n",
            "Average loss after batch 799: 3.0285. Contrastive Term: 0.000\n",
            "Checkpoint saved here: drive/MyDrive/Colab Notebooks/venv_MLAP_test_eval/checkpoints/alpha__0.0_cl__False_cl_all__False_dgi_task__False_depth__3__epoch_2\n",
            "Average training loss: 3.028537175655365\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.061342027278277284 Validation: 0.05407897240741173 Test: 0.05424882991176048\n",
            "MAD global batch averages\n",
            "\tTrain: 0.5127114956825971 Validation: 0.4498292732030088 Test: 0.4498385191642614\n",
            "Train Loss: 3.028537175655365\n",
            "Training epoch: 3/6\n",
            "Average loss after batch 49: 2.8017. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.0646254741785992 Validation: 0.05595038723627057 Test: 0.056719503083636484\n",
            "MAD global batch averages\n",
            "\tTrain: 0.569577195495367 Validation: 0.49824628387160064 Test: 0.5030491701019653\n",
            "Average loss after batch 99: 2.8490. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06583614080364081 Validation: 0.05528487499605526 Test: 0.05659760601668748\n",
            "MAD global batch averages\n",
            "\tTrain: 0.5729268737882376 Validation: 0.4995610954268495 Test: 0.501580480053376\n",
            "Average loss after batch 149: 2.8448. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06797569772547712 Validation: 0.057344287293448 Test: 0.05903493262705947\n",
            "MAD global batch averages\n",
            "\tTrain: 0.5897375154495239 Validation: 0.5127773038407123 Test: 0.5154003759926706\n",
            "Average loss after batch 199: 2.8397. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.06426732954545455 Validation: 0.05362074340029373 Test: 0.05439373163539374\n",
            "MAD global batch averages\n",
            "\tTrain: 0.6079745327681303 Validation: 0.5336054605584698 Test: 0.5385874337039396\n",
            "Average loss after batch 249: 2.8462. Contrastive Term: 0.000\n",
            "\n",
            "Evaluating...\n",
            "Eval Criteria:\n",
            "\tTrain: 0.07563782897657897 Validation: 0.06579816851324936 Test: 0.06540522055147534\n",
            "MAD global batch averages\n",
            "\tTrain: 0.6253327789157629 Validation: 0.5463443068824138 Test: 0.5520454223240155\n",
            "Average loss after batch 299: 2.8486. Contrastive Term: 0.000\n",
            "Checkpoint saved here: drive/MyDrive/Colab Notebooks/venv_MLAP_test_eval/checkpoints/alpha__0.0_cl__False_cl_all__False_dgi_task__False_depth__3__epoch_3\n",
            "\n",
            "\n",
            "Evaluating...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSnBlQOpU3SW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}