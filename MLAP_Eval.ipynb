{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "NOTEBOOK_NAME = \"MLAP_test_eval\"\n",
        "\n",
        "# --- do not change below this ---\n",
        "DRIVE_PATH = \"/content/drive/\"\n",
        "drive.mount(DRIVE_PATH, force_remount=True)\n",
        "\n",
        "# shell commands for directory with space must be\n",
        "# quoted, but not necessary in python\n",
        "COLAB_PATH = \"Colab Notebooks\"\n",
        "COLLAB_PATH_ESC = f\"\\\"{COLAB_PATH}\\\"\"\n",
        "\n",
        "# python path\n",
        "nb_path = (\n",
        "    \"/\".join(('drive/MyDrive', \n",
        "              COLAB_PATH, \n",
        "              \"venv_\" + NOTEBOOK_NAME)\n",
        "    )\n",
        ")\n",
        "\n",
        "# shell path\n",
        "nb_path_bash = (\n",
        "    \"/\".join(('drive/MyDrive', \n",
        "              COLLAB_PATH_ESC, \n",
        "              \"venv_\" + NOTEBOOK_NAME)\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "  os.makedirs(nb_path)\n",
        "except FileExistsError:\n",
        "  # already created in G-drive\n",
        "  print(\"Google Drive Folder already existed.\")\n",
        "\n",
        "try:\n",
        "  # create symlink from drive to workspace\n",
        "  os.symlink(nb_path, \"/content/notebooks\")\n",
        "except FileExistsError:\n",
        "  # already created in G-drive\n",
        "  print(\"Symlink already existed.\")\n",
        "\n",
        "sys.path.insert(0, nb_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFQxATSSWofs",
        "outputId": "9713379b-f6b2-4b0e-e38e-ea309aa8956e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Google Drive Folder already existed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJIm9RQtWpcW",
        "outputId": "9fa3faf4-59cd-429f-e220-ec598caafa53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.0.tar.gz (616 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.2/616.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.0-py3-none-any.whl size=909897 sha256=e98ae6a8830f32193054840524d495696e6b33a99efd38d8e9a09ddd811476db\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/7d/6b/17150450b80b4a3656a84330e22709ccd8dc0f8f4773ba4133\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKVnqZxhXana",
        "outputId": "5119f7e1-20e3-4fe2-d3f5-943dda233243"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.26.15)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (2.0.0+cu118)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (4.65.0)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (67.6.1)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=2c7bf879264fe23878c24f728ddbe917df5b1ec85ec71f4fb814dd759abb400b\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/bb/0d/2d02ec45f29c48d6192476bfb59c5a0e64b605e7212374dd15\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "FamuAT6rV3G6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.utils import dropout_edge, degree, to_undirected, scatter, to_networkx\n",
        "import networkx as nx\n",
        "\n",
        "class ASTNodeEncoder(torch.nn.Module):\n",
        "    '''\n",
        "        Input:\n",
        "            x: default node feature. the first and second column represents node type and node attributes.\n",
        "            depth: The depth of the node in the AST.\n",
        "\n",
        "        Output:\n",
        "            emb_dim-dimensional vector\n",
        "\n",
        "    '''\n",
        "    def __init__(self, emb_dim, num_nodetypes, num_nodeattributes, max_depth):\n",
        "        super(ASTNodeEncoder, self).__init__()\n",
        "\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "        self.type_encoder = torch.nn.Embedding(num_nodetypes, emb_dim)\n",
        "        self.attribute_encoder = torch.nn.Embedding(num_nodeattributes, emb_dim)\n",
        "        self.depth_encoder = torch.nn.Embedding(self.max_depth + 1, emb_dim)\n",
        "\n",
        "        self.node_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(3 * emb_dim, 2 * emb_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(2 * emb_dim, emb_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, depth):\n",
        "        depth[depth > self.max_depth] = self.max_depth\n",
        "        mlp_input = torch.hstack((self.type_encoder(x[:,0]), self.attribute_encoder(x[:,1]), self.depth_encoder(depth)))\n",
        "        return self.node_mlp(mlp_input)\n",
        "\n",
        "\n",
        "\n",
        "def get_vocab_mapping(seq_list, num_vocab):\n",
        "    '''\n",
        "        Input:\n",
        "            seq_list: a list of sequences\n",
        "            num_vocab: vocabulary size\n",
        "        Output:\n",
        "            vocab2idx:\n",
        "                A dictionary that maps vocabulary into integer index.\n",
        "                Additioanlly, we also index '__UNK__' and '__EOS__'\n",
        "                '__UNK__' : out-of-vocabulary term\n",
        "                '__EOS__' : end-of-sentence\n",
        "\n",
        "            idx2vocab:\n",
        "                A list that maps idx to actual vocabulary.\n",
        "\n",
        "    '''\n",
        "\n",
        "    vocab_cnt = {}\n",
        "    vocab_list = []\n",
        "    for seq in seq_list:\n",
        "        for w in seq:\n",
        "            if w in vocab_cnt:\n",
        "                vocab_cnt[w] += 1\n",
        "            else:\n",
        "                vocab_cnt[w] = 1\n",
        "                vocab_list.append(w)\n",
        "\n",
        "    cnt_list = np.array([vocab_cnt[w] for w in vocab_list])\n",
        "    topvocab = np.argsort(-cnt_list, kind = 'stable')[:num_vocab]\n",
        "\n",
        "    print('Coverage of top {} vocabulary:'.format(num_vocab))\n",
        "    print(float(np.sum(cnt_list[topvocab]))/np.sum(cnt_list))\n",
        "\n",
        "    vocab2idx = {vocab_list[vocab_idx]: idx for idx, vocab_idx in enumerate(topvocab)}\n",
        "    idx2vocab = [vocab_list[vocab_idx] for vocab_idx in topvocab]\n",
        "\n",
        "    vocab2idx['__UNK__'] = num_vocab\n",
        "    idx2vocab.append('__UNK__')\n",
        "\n",
        "    vocab2idx['__EOS__'] = num_vocab + 1\n",
        "    idx2vocab.append('__EOS__')\n",
        "\n",
        "    # test the correspondence between vocab2idx and idx2vocab\n",
        "    for idx, vocab in enumerate(idx2vocab):\n",
        "        assert(idx == vocab2idx[vocab])\n",
        "\n",
        "    # test that the idx of '__EOS__' is len(idx2vocab) - 1.\n",
        "    # This fact will be used in decode_arr_to_seq, when finding __EOS__\n",
        "    assert(vocab2idx['__EOS__'] == len(idx2vocab) - 1)\n",
        "\n",
        "    return vocab2idx, idx2vocab\n",
        "\n",
        "def augment_edge(data):\n",
        "    '''\n",
        "        Input:\n",
        "            data: PyG data object\n",
        "        Output:\n",
        "            data (edges are augmented in the following ways):\n",
        "                data.edge_index: Added next-token edge. The inverse edges were also added.\n",
        "                data.edge_attr (torch.Long):\n",
        "                    data.edge_attr[:,0]: whether it is AST edge (0) for next-token edge (1)\n",
        "                    data.edge_attr[:,1]: whether it is original direction (0) or inverse direction (1)\n",
        "    '''\n",
        "\n",
        "    ##### AST edge\n",
        "    edge_index_ast = data.edge_index\n",
        "    edge_attr_ast = torch.zeros((edge_index_ast.size(1), 2))\n",
        "\n",
        "    ##### Inverse AST edge\n",
        "    edge_index_ast_inverse = torch.stack([edge_index_ast[1], edge_index_ast[0]], dim = 0)\n",
        "    edge_attr_ast_inverse = torch.cat([torch.zeros(edge_index_ast_inverse.size(1), 1), torch.ones(edge_index_ast_inverse.size(1), 1)], dim = 1)\n",
        "\n",
        "\n",
        "    ##### Next-token edge\n",
        "\n",
        "    ## Obtain attributed nodes and get their indices in dfs order\n",
        "    # attributed_node_idx = torch.where(data.node_is_attributed.view(-1,) == 1)[0]\n",
        "    # attributed_node_idx_in_dfs_order = attributed_node_idx[torch.argsort(data.node_dfs_order[attributed_node_idx].view(-1,))]\n",
        "\n",
        "    ## Since the nodes are already sorted in dfs ordering in our case, we can just do the following.\n",
        "    attributed_node_idx_in_dfs_order = torch.where(data.node_is_attributed.view(-1,) == 1)[0]\n",
        "\n",
        "    ## build next token edge\n",
        "    # Given: attributed_node_idx_in_dfs_order\n",
        "    #        [1, 3, 4, 5, 8, 9, 12]\n",
        "    # Output:\n",
        "    #    [[1, 3, 4, 5, 8, 9]\n",
        "    #     [3, 4, 5, 8, 9, 12]\n",
        "    edge_index_nextoken = torch.stack([attributed_node_idx_in_dfs_order[:-1], attributed_node_idx_in_dfs_order[1:]], dim = 0)\n",
        "    edge_attr_nextoken = torch.cat([torch.ones(edge_index_nextoken.size(1), 1), torch.zeros(edge_index_nextoken.size(1), 1)], dim = 1)\n",
        "\n",
        "\n",
        "    ##### Inverse next-token edge\n",
        "    edge_index_nextoken_inverse = torch.stack([edge_index_nextoken[1], edge_index_nextoken[0]], dim = 0)\n",
        "    edge_attr_nextoken_inverse = torch.ones((edge_index_nextoken.size(1), 2))\n",
        "\n",
        "    data.edge_index = torch.cat([edge_index_ast, edge_index_ast_inverse, edge_index_nextoken, edge_index_nextoken_inverse], dim = 1)\n",
        "    data.edge_attr = torch.cat([edge_attr_ast,   edge_attr_ast_inverse, edge_attr_nextoken,  edge_attr_nextoken_inverse], dim = 0)\n",
        "\n",
        "    return data\n",
        "\n",
        "def encode_y_to_arr(data, vocab2idx, max_seq_len):\n",
        "    '''\n",
        "    Input:\n",
        "        data: PyG graph object\n",
        "        output: add y_arr to data \n",
        "    '''\n",
        "\n",
        "    # PyG >= 1.5.0\n",
        "    seq = data.y\n",
        "\n",
        "    data.y_arr = encode_seq_to_arr(seq, vocab2idx, max_seq_len)\n",
        "\n",
        "    return data\n",
        "\n",
        "def encode_seq_to_arr(seq, vocab2idx, max_seq_len):\n",
        "    '''\n",
        "    Input:\n",
        "        seq: A list of words\n",
        "        output: add y_arr (torch.Tensor)\n",
        "    '''\n",
        "\n",
        "    augmented_seq = seq[:max_seq_len] + ['__EOS__'] * max(0, max_seq_len - len(seq))\n",
        "    return torch.tensor([[vocab2idx[w] if w in vocab2idx else vocab2idx['__UNK__'] for w in augmented_seq]], dtype = torch.long)\n",
        "\n",
        "\n",
        "def decode_arr_to_seq(arr, idx2vocab):\n",
        "    '''\n",
        "        Input: torch 1d array: y_arr\n",
        "        Output: a sequence of words.\n",
        "    '''\n",
        "\n",
        "    eos_idx_list = (arr == len(idx2vocab) - 1).nonzero() # find the position of __EOS__ (the last vocab in idx2vocab)\n",
        "    if len(eos_idx_list) > 0:\n",
        "        clippted_arr = arr[: torch.min(eos_idx_list)] # find the smallest __EOS__\n",
        "    else:\n",
        "        clippted_arr = arr\n",
        "\n",
        "    return list(map(lambda x: idx2vocab[x], clippted_arr.cpu()))\n",
        "\n",
        "\n",
        "# ---- CAP functions ----\n",
        "# from: https://github.com/CRIPAC-DIG/GCA/blob/cd6a9f0cf06c0b8c48e108a6aab743585f6ba6f1/pGRACE/functional.py\n",
        "# and: https://github.com/CRIPAC-DIG/GCA/blob/cd6a9f0cf06c0b8c48e108a6aab743585f6ba6f1/pGRACE/utils.py\n",
        "\n",
        "def compute_pr(edge_index, damp: float = 0.85, k: int = 10):\n",
        "    # page rank\n",
        "    # interesting comment: https://github.com/CRIPAC-DIG/GCA/issues/4\n",
        "    num_nodes = edge_index.max().item() + 1\n",
        "    deg_out = degree(edge_index[0])\n",
        "    x = torch.ones((num_nodes, )).to(edge_index.device).to(torch.float32)\n",
        "\n",
        "    for i in range(k):\n",
        "        edge_msg = x[edge_index[0]] / deg_out[edge_index[0]]\n",
        "        agg_msg = scatter(edge_msg, edge_index[1], reduce='sum')\n",
        "\n",
        "        x = (1 - damp) * x + damp * agg_msg\n",
        "\n",
        "    return x\n",
        "\n",
        "def eigenvector_centrality(data):\n",
        "    graph = to_networkx(data)\n",
        "    x = nx.eigenvector_centrality_numpy(graph)\n",
        "    x = [x[i] for i in range(data.num_nodes)]\n",
        "    return torch.tensor(x, dtype=torch.float32).to(data.edge_index.device)\n",
        "\n",
        "\n",
        "def drop_feature(x, drop_prob):\n",
        "    drop_mask = torch.empty((x.size(1),), dtype=torch.float32, device=x.device).uniform_(0, 1) < drop_prob\n",
        "    x = x.clone()\n",
        "    x[:, drop_mask] = 0\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def drop_feature_weighted(x, w, p: float, threshold: float = 0.7):\n",
        "    w = w / w.mean() * p\n",
        "    w = w.where(w < threshold, torch.ones_like(w) * threshold)\n",
        "    drop_prob = w.repeat(x.size(0)).view(x.size(0), -1)\n",
        "\n",
        "    drop_mask = torch.bernoulli(drop_prob).to(torch.bool)\n",
        "\n",
        "    x = x.clone()\n",
        "    x[drop_mask] = 0.\n",
        "\n",
        "    return x\n",
        "\n",
        "def drop_feature_weighted_2(x, w, p: float, threshold: float = 0.7, dgi_task=False):\n",
        "    w = w / w.mean() * p\n",
        "    # if (dgi_task):\n",
        "    #     threshold = 0.9\n",
        "\n",
        "    w = w.where(w < threshold, torch.ones_like(w) * threshold)\n",
        "    drop_prob = w\n",
        "\n",
        "    if (dgi_task):\n",
        "        drop_mask = torch.bernoulli(1. - drop_prob).to(torch.bool)\n",
        "    else:\n",
        "        drop_mask = torch.bernoulli(drop_prob).to(torch.bool)\n",
        "\n",
        "    x = x.clone()\n",
        "    x[:, drop_mask] = 0.\n",
        "\n",
        "    return x\n",
        "\n",
        "def feature_drop_weights(x, node_c):\n",
        "    x = x.to(torch.bool).to(torch.float32)\n",
        "    w = x.t() @ node_c\n",
        "    w = w.log()\n",
        "    s = (w.max() - w) / (w.max() - w.mean())\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "def feature_drop_weights_dense(x, node_c):\n",
        "    x = x.abs()\n",
        "    w = x.t() @ node_c\n",
        "    w = w.log()\n",
        "    s = (w.max() - w) / (w.max() - w.mean())\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "def drop_edge_weighted(edge_index, edge_weights, p: float, threshold: float = 1., dgi_task=False):\n",
        "    edge_weights = edge_weights / edge_weights.mean() * p\n",
        "    # if (dgi_task):\n",
        "    #     threshold = 0.9\n",
        "\n",
        "    edge_weights = edge_weights.where(edge_weights < threshold, torch.ones_like(edge_weights) * threshold)\n",
        "\n",
        "    if (dgi_task): # drop edges by importance\n",
        "        sel_mask = torch.bernoulli(edge_weights).to(torch.bool)\n",
        "    else:\n",
        "        sel_mask = torch.bernoulli(1. - edge_weights).to(torch.bool)\n",
        "\n",
        "    return edge_index[:, sel_mask]\n",
        "\n",
        "\n",
        "def degree_drop_weights(edge_index):\n",
        "    edge_index_ = to_undirected(edge_index)\n",
        "    deg = degree(edge_index_[1])\n",
        "    deg_col = deg[edge_index[1]].to(torch.float32)\n",
        "    s_col = torch.log(deg_col)\n",
        "    weights = (s_col.max() - s_col) / (s_col.max() - s_col.mean())\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "def pr_drop_weights(edge_index, aggr: str = 'sink', k: int = 10):\n",
        "    pv = compute_pr(edge_index, k=k)\n",
        "    pv_row = pv[edge_index[0]].to(torch.float32)\n",
        "    pv_col = pv[edge_index[1]].to(torch.float32)\n",
        "    s_row = torch.log(pv_row)\n",
        "    s_col = torch.log(pv_col)\n",
        "    if aggr == 'sink':\n",
        "        s = s_col\n",
        "    elif aggr == 'source':\n",
        "        s = s_row\n",
        "    elif aggr == 'mean':\n",
        "        s = (s_col + s_row) * 0.5\n",
        "    else:\n",
        "        s = s_col\n",
        "    weights = (s.max() - s) / (s.max() - s.mean())\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "def evc_drop_weights(data):\n",
        "    evc = eigenvector_centrality(data)\n",
        "    evc = evc.where(evc > 0, torch.zeros_like(evc))\n",
        "    evc = evc + 1e-8\n",
        "    s = evc.log()\n",
        "\n",
        "    edge_index = data.edge_index\n",
        "    s_row, s_col = s[edge_index[0]], s[edge_index[1]]\n",
        "    s = s_col\n",
        "\n",
        "    return (s.max() - s) / (s.max() - s.mean())\n",
        "\n",
        "def graph_perturb(data, drop_scheme='pr'):\n",
        "  if drop_scheme == 'degree':\n",
        "      drop_weights = degree_drop_weights(data.edge_index)\n",
        "      edge_index_ = to_undirected(data.edge_index)\n",
        "      node_deg = degree(edge_index_[1])\n",
        "      feature_weights = feature_drop_weights(data.x, node_c=node_deg)\n",
        "  elif drop_scheme == 'pr':\n",
        "      drop_weights = pr_drop_weights(data.edge_index, aggr='sink', k=200)\n",
        "      node_pr = compute_pr(data.edge_index)\n",
        "      feature_weights = feature_drop_weights(data.x, node_c=node_pr)\n",
        "  elif drop_scheme == 'evc':\n",
        "      drop_weights = evc_drop_weights(data)\n",
        "      node_evc = eigenvector_centrality(data)\n",
        "      feature_weights = feature_drop_weights(data.x, node_c=node_evc)\n",
        "  else:\n",
        "      feature_weights = torch.ones((data.x.size(1),))\n",
        "      drop_weights = None\n",
        "  \n",
        "  return feature_weights, drop_weights\n",
        "\n",
        "def drop_edge(data, drop_edge_rate, drop_weights, drop_scheme='pr', drop_edge_weighted_threshold=0.7, dgi_task=False):\n",
        "  if drop_scheme == 'uniform':\n",
        "      return dropout_edge(data.edge_index, p=drop_edge_rate)[0]\n",
        "  elif drop_scheme in ['degree', 'evc', 'pr']:\n",
        "      return drop_edge_weighted(\n",
        "          data.edge_index, \n",
        "          drop_weights, \n",
        "          p=drop_edge_rate, \n",
        "          threshold=drop_edge_weighted_threshold,\n",
        "          dgi_task=dgi_task\n",
        "        )\n",
        "  else:\n",
        "      raise Exception(f'undefined drop scheme: {drop_scheme}')\n",
        "\n",
        "def get_contrastive_graph_pair(data, drop_scheme='pr', drop_feature_rates=(0.7, 0.7), drop_edge_rates=(0.5, 0.5), dgi_task=False):\n",
        "  # use augmentation scheme to determine the weights of each node\n",
        "  # i.e. pagerank, eigenvector centrality, node degree\n",
        "  feat_weights, drop_weights = graph_perturb(data, drop_scheme)\n",
        "\n",
        "  # apply drop edge according to computed features\n",
        "  dr_e_1, dr_e_2 = drop_edge_rates\n",
        "  edge_index_1 = drop_edge(data, dr_e_1, drop_weights, drop_scheme, dgi_task=dgi_task)\n",
        "\n",
        "  if (not dgi_task):\n",
        "    edge_index_2 = drop_edge(data, dr_e_2, drop_weights, drop_scheme)\n",
        "\n",
        "  dr_f_1, dr_f_2 = drop_feature_rates\n",
        "\n",
        "  if drop_scheme in ['pr', 'degree', 'evc']:\n",
        "    # graph-aware drop feature\n",
        "    x_1 = drop_feature_weighted_2(data.x, feat_weights, dr_f_1, dgi_task=dgi_task)\n",
        "    #e_1 = drop_feature_weighted_2(data.edge_attr, feat_weights, dr_f_1)\n",
        "\n",
        "    if (not dgi_task):\n",
        "        x_2 = drop_feature_weighted_2(data.x, feat_weights, dr_f_2, dgi_task=dgi_task)\n",
        "        #e_2 = drop_feature_weighted_2(data.edge_attr, feat_weights, dr_f_2)\n",
        "  else:\n",
        "    # naive drop feature\n",
        "    x_1 = drop_feature(data.x, dr_f_1)\n",
        "    #e_1 = drop_feature(data.edge_attr, dr_f_1)\n",
        "    \n",
        "    x_2 = drop_feature(data.x, dr_f_2)\n",
        "    e_2 = drop_feature(data.edge_attr, dr_f_2)\n",
        "  \n",
        "  if dgi_task:\n",
        "      return (x_1, edge_index_1)\n",
        "\n",
        "  return (\n",
        "      # graph 1\n",
        "      (x_1, edge_index_1),\n",
        "      # graph 2\n",
        "      (x_2, edge_index_2)\n",
        "  )"
      ],
      "metadata": {
        "id": "6QXwE3BnV2vf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GIN"
      ],
      "metadata": {
        "id": "ng-TvX2UVlWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops\n",
        "\n",
        "from torch.nn import Linear, BatchNorm1d\n",
        "\n",
        "class GINConv(MessagePassing):\n",
        "    def __init__(self, dim_h, mlp, **kwargs):\n",
        "        super(GINConv, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.mlp = mlp\n",
        "\n",
        "        self.bn = BatchNorm1d(dim_h)\n",
        "\n",
        "        self.edge_encoder = Linear(2, dim_h)\n",
        "\n",
        "    \n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        edge_attr = self.edge_encoder(edge_attr)\n",
        "\n",
        "        edge_index, _ = remove_self_loops(edge_index)\n",
        "\n",
        "        output = self.mlp(self.propagate(edge_index, x=x, edge_attr=edge_attr))\n",
        "        return self.bn(output)\n",
        "    \n",
        "    def message(self, x_j, edge_attr):\n",
        "        return x_j + edge_attr\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        return aggr_out + x\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__"
      ],
      "metadata": {
        "id": "8u0cRmJ1VkKV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoders"
      ],
      "metadata": {
        "id": "KSAs0mAoVjXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class LinearDecoder(torch.nn.Module):\n",
        "    def __init__(self, dim_h, max_seq_len, vocab2idx, device):\n",
        "        super().__init__()\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.vocab2idx = vocab2idx\n",
        "\n",
        "        self.decoders = nn.ModuleList([nn.Linear(dim_h, len(vocab2idx)) for _ in range(max_seq_len)])\n",
        "\n",
        "    def forward(self, batch_size, layer_reps, labels, training=False):\n",
        "        return [d(layer_reps[-1]) for d in self.decoders]\n",
        "\n",
        "\n",
        "class LSTMDecoder(torch.nn.Module):\n",
        "    def __init__(self, dim_h, max_seq_len, vocab2idx, device):\n",
        "        super(LSTMDecoder, self).__init__()\n",
        "        \n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.vocab2idx = vocab2idx\n",
        "\n",
        "        self.lstm = nn.LSTMCell(dim_h, dim_h)\n",
        "        self.w_hc = nn.Linear(dim_h * 2, dim_h)\n",
        "        self.layernorm = nn.LayerNorm(dim_h)\n",
        "        self.vocab_encoder = nn.Embedding(len(vocab2idx), dim_h)\n",
        "        self.vocab_bias = nn.Parameter(torch.zeros(len(vocab2idx)))\n",
        "\n",
        "        self.device = device\n",
        "    \n",
        "    def forward(self, batch_size, layer_reps, labels, training=False):\n",
        "        if (training):\n",
        "            batched_label = torch.vstack([encode_seq_to_arr(label, self.vocab2idx, self.max_seq_len - 1) for label in labels])\n",
        "            batched_label = torch.hstack((torch.zeros((batch_size, 1), dtype=torch.int64), batched_label))\n",
        "            true_emb = self.vocab_encoder(batched_label.to(device=self.device))\n",
        "        \n",
        "        h_t, c_t = layer_reps[-1].clone(), layer_reps[-1].clone()\n",
        "\n",
        "        layer_reps = layer_reps.transpose(0,1)\n",
        "        output = []\n",
        "\n",
        "        pred_emb = self.vocab_encoder(torch.zeros((batch_size), dtype=torch.int64, device=self.device))\n",
        "        vocab_mat = self.vocab_encoder(torch.arange(len(self.vocab2idx), dtype=torch.int64, device=self.device))\n",
        "\n",
        "        for i in range(self.max_seq_len):\n",
        "            if (training): \n",
        "                # teacher forcing\n",
        "                input = true_emb[:, i]\n",
        "            else:\n",
        "                input = pred_emb\n",
        "            \n",
        "            h_t, c_t = self.lstm(input, (h_t, c_t))\n",
        "\n",
        "            # (batch_size, L + 1)\n",
        "            a = F.softmax(torch.bmm(layer_reps, h_t.unsqueeze(-1)).squeeze(-1), dim=1)  \n",
        "            context = torch.bmm(a.unsqueeze(1), layer_reps).squeeze(1)\n",
        "\n",
        "            # (batch_size, dim_h)\n",
        "            pred_emb = torch.tanh(self.layernorm(self.w_hc(torch.hstack((h_t, context)))))  \n",
        "\n",
        "            # (batch_size, len(vocab)) x max_seq_len\n",
        "            output.append(torch.matmul(pred_emb, vocab_mat.T) + self.vocab_bias.unsqueeze(0))\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "JhqdRjDJVpbo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLAP"
      ],
      "metadata": {
        "id": "WBwnEmwhVxwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear, Sequential, ReLU, ELU, Sigmoid\n",
        "\n",
        "from torch_geometric.nn.conv import GINConv\n",
        "from torch_geometric.nn.norm import GraphNorm\n",
        "from torch_geometric.nn.glob import AttentionalAggregation\n",
        "\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "\n",
        "class DISC(torch.nn.Module):\n",
        "    def __init__(self, dim_h):\n",
        "        super(DISC, self).__init__()\n",
        "\n",
        "        W = torch.empty(dim_h, dim_h)\n",
        "        torch.nn.init.xavier_normal_(W)\n",
        "\n",
        "        self.W = torch.nn.Parameter(W)\n",
        "        self.W.requires_grad = True\n",
        "\n",
        "        self.sig = Sigmoid()\n",
        "    \n",
        "    def forward(self, h, s):\n",
        "        out = torch.matmul(self.W, s)\n",
        "        out = torch.matmul(h, out.unsqueeze(-1))\n",
        "        return self.sig(out)\n",
        "\n",
        "\n",
        "class MLAP_GIN(torch.nn.Module):\n",
        "    def __init__(self, dim_h, batch_size, depth, node_encoder, norm=False, residual=False, dropout=False):\n",
        "        super(MLAP_GIN, self).__init__()\n",
        "\n",
        "        self.dim_h = dim_h\n",
        "        self.batch_size = batch_size\n",
        "        self.depth = depth\n",
        "\n",
        "        self.node_encoder = node_encoder\n",
        "\n",
        "        self.norm = norm\n",
        "        self.residual = residual\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.loss_fn = torch.nn.BCELoss(reduction='sum')\n",
        "        self.discriminator = DISC(dim_h)\n",
        "\n",
        "        # non-linear projection function for cl task\n",
        "        self.projection = Sequential(\n",
        "            Linear(dim_h, int(dim_h/8)),\n",
        "            ELU(),\n",
        "            Linear(int(dim_h/8), dim_h)\n",
        "        )\n",
        "\n",
        "        # GIN layers\n",
        "        self.layers = torch.nn.ModuleList(\n",
        "            [GINConv(Sequential(\n",
        "                Linear(dim_h, dim_h),\n",
        "                ReLU(),\n",
        "                Linear(dim_h, dim_h))) for _ in range(depth)])\n",
        "            \n",
        "        # normalization layers\n",
        "        self.norm = torch.nn.ModuleList([GraphNorm(dim_h) for _ in range(self.depth)])\n",
        "        \n",
        "        # layer-wise attention poolings\n",
        "        self.att_poolings = torch.nn.ModuleList(\n",
        "            [AttentionalAggregation(\n",
        "                Sequential(Linear(self.dim_h, 2*self.dim_h), \n",
        "                           ReLU(), \n",
        "                           Linear(2*self.dim_h, 1))) for _ in range(depth)])\n",
        "        \n",
        "    def contrastive_loss(self, g1_x, g2_x):\n",
        "        # compute projections + L2 row-wise normalizations\n",
        "        g1_projections = self.projection(g1_x)\n",
        "        g1_projections = torch.nn.functional.normalize(g1_projections, p=2, dim=1)\n",
        "        g2_projections = self.projection(g2_x)\n",
        "        g2_projections = torch.nn.functional.normalize(g2_projections, p=2, dim=1)\n",
        "        \n",
        "        g1_proj_T = torch.transpose(g1_projections, 0, 1)\n",
        "        g2_proj_T = torch.transpose(g2_projections, 0, 1)\n",
        "\n",
        "        inter_g1 = torch.exp(torch.matmul(g1_projections, g1_proj_T))\n",
        "        inter_g2 = torch.exp(torch.matmul(g2_projections, g2_proj_T))\n",
        "        intra_view = torch.exp(torch.matmul(g1_projections, g2_proj_T))\n",
        "\n",
        "        # main diagonal\n",
        "        corresponding_terms = torch.diagonal(intra_view, 0) \n",
        "        non_matching_intra = torch.diagonal(intra_view, -1).sum()\n",
        "        non_matching_inter_g1 = torch.diagonal(inter_g1, -1).sum()\n",
        "        non_matching_inter_g2 = torch.diagonal(inter_g2, -1).sum()\n",
        "\n",
        "        # inter-view pairs using g1\n",
        "        corresponding_terms_g1 = corresponding_terms / (corresponding_terms + non_matching_inter_g1 + non_matching_intra)\n",
        "        corresponding_terms_g1 = torch.log(corresponding_terms_g1)\n",
        "\n",
        "        # inter-view pairs using g2\n",
        "        corresponding_terms_g2 = corresponding_terms / (corresponding_terms + non_matching_inter_g2 + non_matching_intra)\n",
        "        corresponding_terms_g2 = torch.log(corresponding_terms_g2)\n",
        "\n",
        "        loss = (corresponding_terms_g1.sum() + corresponding_terms_g2.sum()) / (g1_x.shape[0] + g2_x.shape[0])\n",
        "        \n",
        "        loss = loss / self.batch_size\n",
        "\n",
        "        return loss\n",
        "    \n",
        "    def layer_loop(self, x, edge_index, batch, cl=False, cl_all=False, dgi_task=False):\n",
        "\n",
        "        cl_embs = []\n",
        "        for d in range(self.depth):\n",
        "            x_in = x\n",
        "\n",
        "            x = self.layers[d](x, edge_index)\n",
        "            if (self.norm):\n",
        "                x = self.norm[d](x, batch)\n",
        "            if (d < self.depth - 1):\n",
        "                x = F.relu(x)\n",
        "            if (self.dropout):\n",
        "                x = F.dropout(x)\n",
        "            if (self.residual):\n",
        "                x = x + x_in\n",
        "\n",
        "            if (not cl):\n",
        "                h_g = self.att_poolings[d](x, batch)\n",
        "                self.graph_embs.append(h_g)\n",
        "\n",
        "            if ((cl and cl_all) or (cl and (d == self.depth-1)) or (dgi_task and (d == self.depth-1))):\n",
        "                cl_embs += [x]\n",
        "            \n",
        "        return cl_embs\n",
        "\n",
        "    def forward(self, batched_data, cl=False, cl_all=False, dgi_task=False):\n",
        "        self.graph_embs = []\n",
        "\n",
        "        # non-augmented graph\n",
        "        # note: populates self.graph_embs\n",
        "\n",
        "        node_depth = batched_data.node_depth\n",
        "        x_emb = self.node_encoder(batched_data.x, node_depth.view(-1,))\n",
        "        edge_index = batched_data.edge_index\n",
        "        batch = batched_data.batch\n",
        "\n",
        "        self.layer_loop(x_emb, edge_index, batch, dgi_task=dgi_task)\n",
        "\n",
        "        agg = self.aggregate()\n",
        "        self.graph_embs.append(agg)\n",
        "        output = torch.stack(self.graph_embs, dim=0)\n",
        "\n",
        "        # # dgi task\n",
        "        dgi_loss = 0\n",
        "        if (dgi_task):\n",
        "            for i in range(int(self.batch_size / 5)):\n",
        "                g = batched_data.get_example(i)\n",
        "                g_clone = g.clone()\n",
        "                nd = g.node_depth\n",
        "                b = g.batch\n",
        "                g_clone.x = self.node_encoder(g_clone.x, nd.view(-1,).clone())\n",
        "                g_diff = get_contrastive_graph_pair(g_clone, dgi_task=True)\n",
        "\n",
        "                g_diff_embs = self.layer_loop(g_diff[0], g_diff[1], b, dgi_task=True)[0]\n",
        "\n",
        "                g.x = self.node_encoder(g.x, nd.view(-1,).clone())\n",
        "                g_embs = self.layer_loop(g.x, g.edge_index, g.batch, dgi_task=True)[0]\n",
        "\n",
        "                # dgi objective on final_layer_embs, g_diff_embs, and output\n",
        "                agg = agg.clone()\n",
        "                positive = self.discriminator(g_embs, agg[i])\n",
        "                ones = torch.ones_like(positive)\n",
        "                negative = self.discriminator(g_diff_embs, agg[i])\n",
        "                zeros = torch.zeros_like(negative)\n",
        "\n",
        "                dgi_loss += (self.loss_fn(positive, ones) + self.loss_fn(negative, zeros)) / (positive.shape[0] + negative.shape[0])\n",
        "            \n",
        "            dgi_loss /= int(self.batch_size / 5)\n",
        "\n",
        "        # contrastive learning task\n",
        "        \n",
        "        cl_loss = 0\n",
        "\n",
        "        if (cl):\n",
        "            for i in range(int(self.batch_size / 5)):\n",
        "                g = batched_data.get_example(i)\n",
        "                g_clone = g.clone()\n",
        "                nd = g.node_depth\n",
        "                g_clone.x = self.node_encoder(g_clone.x, nd.view(-1,).clone())\n",
        "                g1, g2 = get_contrastive_graph_pair(g_clone)\n",
        "\n",
        "                b1 = g.batch\n",
        "                g1_x = g1[0].clone()\n",
        "                g1_edge_index = g1[1]\n",
        "                g1_embs = self.layer_loop(g1_x, g1_edge_index, b1, cl=cl, cl_all=cl_all)\n",
        "\n",
        "                b2 = g.batch\n",
        "                g2_x = g2[0].clone()\n",
        "                g2_edge_index = g2[1]\n",
        "                g2_embs = self.layer_loop(g2_x, g2_edge_index, b2, cl=cl, cl_all=cl_all)\n",
        "\n",
        "                batch_cl_loss = 0\n",
        "                for j in range(len(g1_embs)):\n",
        "                    batch_cl_loss += self.contrastive_loss(g1_embs[j], g2_embs[j])\n",
        "                    pass\n",
        "                \n",
        "                batch_cl_loss = batch_cl_loss / len(g1_embs)\n",
        "\n",
        "                cl_loss = cl_loss + batch_cl_loss\n",
        "            \n",
        "            cl_loss /= int(self.batch_size / 5)\n",
        "\n",
        "        return output, cl_loss, dgi_loss\n",
        "    \n",
        "    def aggregate(self):\n",
        "        pass\n",
        "\n",
        "class MLAP_Sum(MLAP_GIN):\n",
        "    def aggregate(self):\n",
        "        return torch.stack(self.graph_embs, dim=0).sum(dim=0)\n",
        "\n",
        "class MLAP_Weighted(MLAP_GIN):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.weight = torch.nn.Parameter(torch.ones(self.depth, 1, 1))\n",
        "\n",
        "    def aggregate(self):\n",
        "        a = F.softmax(self.weight, dim=0)\n",
        "        h = torch.stack(self.graph_embs, dim=0)\n",
        "        return (a * h).sum(dim=0)"
      ],
      "metadata": {
        "id": "NDywjQj9VyVd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "6fnFG6_RV714"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, batch_size, depth, dim_h, max_seq_len, node_encoder, vocab2idx, device):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.depth = depth\n",
        "        self.dim_h = dim_h\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        self.node_encoder = node_encoder\n",
        "\n",
        "        self.vocab2idx = vocab2idx\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.gnn = MLAP_Weighted(dim_h, batch_size, depth, node_encoder, norm=True, residual=True, dropout=True)\n",
        "\n",
        "        self.decoder = LinearDecoder(dim_h, max_seq_len, vocab2idx, device)\n",
        "\n",
        "    def forward(self, batched_data, labels, training=False, cl=False, cl_all=False, dgi_task=False):\n",
        "\n",
        "        embeddings, cl_loss, dgi_loss = self.gnn(batched_data, cl=cl, cl_all=cl_all, dgi_task=dgi_task)\n",
        "        predictions = self.decoder(len(labels), embeddings, labels, training=training)\n",
        "\n",
        "        # for each batch, the prediction for the ith word is a logit\n",
        "        # decoding each prediction to a word is done in the evaluation task in main\n",
        "\n",
        "        return predictions, cl_loss, dgi_loss"
      ],
      "metadata": {
        "id": "7ft4PTPWV8eO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $nb_path_bash && mkdir \"checkpoints\""
      ],
      "metadata": {
        "id": "1iErB7DcYCXm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "BwGxp_PRWAMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
        "\n",
        "\n",
        "\n",
        "def train(model, device, loader, optimizer, scheduler, multicls_criterion, epoch, alpha=0.05, \n",
        "        cl=False, cl_all=False, dgi_task=False):\n",
        "\n",
        "    loss_accum = 0\n",
        "    chkpt_folder = nb_path + '/checkpoints/epoch' + str(epoch)\n",
        "    if (not os.path.exists(chkpt_folder)):\n",
        "        os.mkdir(chkpt_folder)\n",
        "\n",
        "    for step, batch in enumerate(loader):\n",
        "\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
        "            pass\n",
        "        else:\n",
        "            labels = [batch.y[i] for i in range(len(batch.y))]\n",
        "            pred_list, cl_loss, dgi_loss = model(batch, labels, training=True, cl=cl, cl_all=cl_all, dgi_task=dgi_task)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss = 0\n",
        "            for i in range(len(pred_list)):\n",
        "                loss += (1-alpha) * multicls_criterion(pred_list[i].to(torch.float32), batch.y_arr[:, i])\n",
        "\n",
        "            loss /= len(pred_list)\n",
        "\n",
        "            if (cl and dgi_task):\n",
        "                raise Exception(\"Cannot use both a contrastive and dgi loss term\\n\")\n",
        "        \n",
        "            if (cl):\n",
        "                loss -= alpha * cl_loss\n",
        "\n",
        "            if (dgi_task):\n",
        "                loss -= alpha * dgi_loss\n",
        "\n",
        "            with torch.autograd.set_detect_anomaly(True):\n",
        "                loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_accum += loss.item()\n",
        "            print('Average loss after batch ' + str(step) + ': ' + str(loss_accum / (step + 1)))\n",
        "        \n",
        "        if ((step+1) % 35 == 0 or step == len(loader)-1): # save model after every 35 batches\n",
        "            print(\"Checkpoint saved.\")\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'loss': loss_accum / (step + 1),\n",
        "            }, chkpt_folder + '/model' + str((step+1) // 35) + '.pt')\n",
        "\n",
        "    print('Average training loss: {}'.format(loss_accum / (step + 1)))\n",
        "    return loss_accum / (step + 1)\n",
        "\n",
        "def eval(model, device, loader, evaluator, arr_to_seq):\n",
        "\n",
        "    seq_ref_list = []\n",
        "    seq_pred_list = []\n",
        "\n",
        "    for step, batch in enumerate(loader):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        if batch.x.shape[0] == 1:\n",
        "            pass\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                labels = [batch.y[i] for i in range(len(batch.y))]\n",
        "                pred_list, _, _ = model(batch, labels) # no cl by default\n",
        "\n",
        "            mat = []\n",
        "            for i in range(len(pred_list)):\n",
        "                mat.append(torch.argmax(pred_list[i], dim=1).view(-1, 1))\n",
        "            mat = torch.cat(mat, dim=1)\n",
        "\n",
        "            seq_pred = [arr_to_seq(arr) for arr in mat]\n",
        "\n",
        "            seq_ref = labels\n",
        "\n",
        "            seq_ref_list.extend(seq_ref)\n",
        "            seq_pred_list.extend(seq_pred)\n",
        "\n",
        "    input_dict = {\"seq_ref\": seq_ref_list, \"seq_pred\": seq_pred_list}\n",
        "    return evaluator.eval(input_dict)\n",
        "\n",
        "def randomly_mask(dataset, size):\n",
        "    bool_mask = np.zeros(len(dataset), dtype=bool)\n",
        "    bool_mask[:size] = True\n",
        "    np.random.shuffle(bool_mask)\n",
        "    out = dataset[bool_mask]\n",
        "    return out\n",
        "\n",
        "\n",
        "def main(starting_chkpt=None, cl=False, cl_all=False, dgi_task=False):\n",
        "    # constants\n",
        "    dataset_name = \"ogbg-code2\"\n",
        "\n",
        "    num_vocab = 5000\n",
        "    max_seq_len = 5\n",
        "\n",
        "    depth = 3\n",
        "    batch_size = 50\n",
        "    epochs = 50\n",
        "    learning_rate = 0.001\n",
        "    step_size = 10\n",
        "    decay_rate = 0.1\n",
        "    weight_decay = 0.00005\n",
        "\n",
        "    dim_h = 512\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    dataset = PygGraphPropPredDataset(dataset_name)\n",
        "\n",
        "    split_idx = dataset.get_idx_split()\n",
        "\n",
        "    vocab2idx, idx2vocab = get_vocab_mapping([dataset.data.y[i] for i in split_idx['train']], num_vocab)\n",
        "\n",
        "    dataset.transform = transforms.Compose([augment_edge, lambda data: encode_y_to_arr(data, vocab2idx, max_seq_len)])\n",
        "\n",
        "    evaluator = Evaluator(dataset_name)\n",
        "\n",
        "    full_training = randomly_mask(dataset[split_idx[\"train\"]], batch_size*400)\n",
        "    full_valid = randomly_mask(dataset[split_idx[\"valid\"]], batch_size*400)\n",
        "    full_test = randomly_mask(dataset[split_idx[\"test\"]], batch_size*400)\n",
        "\n",
        "    train_loader = DataLoader(full_training, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(full_valid, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(full_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    nodetypes_mapping = pd.read_csv(os.path.join(dataset.root, 'mapping', 'typeidx2type.csv.gz'))\n",
        "    nodeattributes_mapping = pd.read_csv(os.path.join(dataset.root, 'mapping', 'attridx2attr.csv.gz'))\n",
        "\n",
        "    node_encoder = ASTNodeEncoder(dim_h, num_nodetypes=len(nodetypes_mapping['type']), num_nodeattributes=len(nodeattributes_mapping['attr']), max_depth=20)\n",
        "\n",
        "    model = Model(batch_size, depth, dim_h, max_seq_len, node_encoder, vocab2idx, device).to(device)\n",
        "\n",
        "    num_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f'#Params: {num_params}')\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=decay_rate)\n",
        "\n",
        "    multicls_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    starting_epoch = 1\n",
        "\n",
        "    if (starting_chkpt != None):\n",
        "        checkpoint = torch.load(starting_chkpt)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "        starting_epoch = checkpoint['epoch']\n",
        "\n",
        "\n",
        "    valid_curve = []\n",
        "    test_curve = []\n",
        "    train_curve = []\n",
        "    trainL_curve = []\n",
        "\n",
        "    for epoch in range(starting_epoch, epochs + 1):\n",
        "        print (datetime.datetime.now().strftime('%Y.%m.%d-%H:%M:%S'))\n",
        "        print(\"Epoch {} training...\".format(epoch))\n",
        "        print (\"lr: \", optimizer.param_groups[0]['lr'])\n",
        "        train_loss = train(model, device, train_loader, optimizer, scheduler, multicls_criterion, epoch, cl=cl, cl_all=cl_all, dgi_task=dgi_task)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print('Evaluating...')\n",
        "        train_perf = eval(model, device, train_loader, evaluator, arr_to_seq=lambda arr: decode_arr_to_seq(arr, idx2vocab))\n",
        "        valid_perf = eval(model, device, valid_loader, evaluator, arr_to_seq=lambda arr: decode_arr_to_seq(arr, idx2vocab))\n",
        "        test_perf = eval(model, device, test_loader, evaluator, arr_to_seq=lambda arr: decode_arr_to_seq(arr, idx2vocab))\n",
        "\n",
        "        print('Train:', train_perf[dataset.eval_metric],\n",
        "              'Validation:', valid_perf[dataset.eval_metric],\n",
        "              'Test:', test_perf[dataset.eval_metric],\n",
        "              'Train loss:', train_loss)\n",
        "\n",
        "        train_curve.append(train_perf[dataset.eval_metric])\n",
        "        valid_curve.append(valid_perf[dataset.eval_metric])\n",
        "        test_curve.append(test_perf[dataset.eval_metric])\n",
        "        trainL_curve.append(train_loss)\n",
        "\n",
        "    print('F1')\n",
        "    best_val_epoch = np.argmax(np.array(valid_curve))\n",
        "    best_train = max(train_curve)\n",
        "    print('Finished training!')\n",
        "    print('Best validation score: {}'.format(valid_curve[best_val_epoch]))\n",
        "    print('Test score: {}'.format(test_curve[best_val_epoch]))\n",
        "\n",
        "    print('Finished test: {}, Validation: {}, Train: {}, epoch: {}, best train: {}, best loss: {}'\n",
        "          .format(test_curve[best_val_epoch], valid_curve[best_val_epoch], train_curve[best_val_epoch],\n",
        "                  best_val_epoch, best_train, min(trainL_curve)))"
      ],
      "metadata": {
        "id": "mh7dpE0hWAx3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(cl=True, cl_all=False, dgi_task=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qHPw1q10Xfvq",
        "outputId": "205e1d74-b689-47ee-bf47-4e0aaa50e714"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage of top 5000 vocabulary:\n",
            "0.9025832389087423\n",
            "#Params: 23612920\n",
            "2023.04.24-13:11:02\n",
            "Epoch 1 training...\n",
            "lr:  0.001\n",
            "Average loss after batch 0: 8.241864204406738\n",
            "Average loss after batch 1: 6.913753509521484\n",
            "Average loss after batch 2: 6.206079483032227\n",
            "Average loss after batch 3: 5.8330397605896\n",
            "Average loss after batch 4: 5.482022762298584\n",
            "Average loss after batch 5: 5.187169591585795\n",
            "Average loss after batch 6: 4.879151548658099\n",
            "Average loss after batch 7: 4.696402192115784\n",
            "Average loss after batch 8: 4.610397974650065\n",
            "Average loss after batch 9: 4.477727293968201\n",
            "Average loss after batch 10: 4.388842647725886\n",
            "Average loss after batch 11: 4.297240157922109\n",
            "Average loss after batch 12: 4.25710654258728\n",
            "Average loss after batch 13: 4.2228391000202725\n",
            "Average loss after batch 14: 4.192548052469889\n",
            "Average loss after batch 15: 4.130906954407692\n",
            "Average loss after batch 16: 4.0892495968762566\n",
            "Average loss after batch 17: 4.078388147883945\n",
            "Average loss after batch 18: 4.034598701878598\n",
            "Average loss after batch 19: 4.005221486091614\n",
            "Average loss after batch 20: 3.973212276186262\n",
            "Average loss after batch 21: 3.9399526444348423\n",
            "Average loss after batch 22: 3.921650285306184\n",
            "Average loss after batch 23: 3.8979438940684\n",
            "Average loss after batch 24: 3.8769667243957517\n",
            "Average loss after batch 25: 3.8470631654445944\n",
            "Average loss after batch 26: 3.8231906625959606\n",
            "Average loss after batch 27: 3.796611257961818\n",
            "Average loss after batch 28: 3.803902001216494\n",
            "Average loss after batch 29: 3.7947075525919596\n",
            "Average loss after batch 30: 3.7784295466638382\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c8b3b3917135>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgi_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-e128739890d5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(starting_chkpt, cl, cl_all, dgi_task)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {} training...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"lr: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticls_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcl_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgi_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdgi_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e128739890d5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, loader, optimizer, scheduler, multicls_criterion, epoch, alpha, cl, cl_all, dgi_task)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wndF4IApYz9o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}